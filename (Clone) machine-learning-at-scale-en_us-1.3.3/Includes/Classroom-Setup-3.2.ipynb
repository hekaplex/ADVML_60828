{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "517cb7e3-b65f-46f5-a84b-c67e36f5cbbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4cee3668-bbca-4a0c-bbbd-a3db0e7dda2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "import pandas as pd\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1fa04e3a-8fae-4ae2-ad2a-f634744164ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "@DBAcademyHelper.add_method\n",
    "def create_large_wine_quality_table(self):\n",
    "    spark.sql(f\"USE CATALOG {DA.catalog_name}\")\n",
    "    spark.sql(f\"USE SCHEMA {DA.schema_name}\")\n",
    "    \n",
    "    # Load the original wine dataset\n",
    "    data_path = f\"{DA.paths.datasets.wine_quality}/data\"\n",
    "    df = spark.read.format(\"delta\").load(data_path)\n",
    "\n",
    "    # Function to create a larger dataset for demonstration purposes\n",
    "    def generate_large_wine_dataset(df, num_copies=100):\n",
    "        pandas_df = df.toPandas()  # Convert to Pandas for duplication\n",
    "        large_df = pd.concat([pandas_df.sample(frac=1).reset_index(drop=True)] * num_copies, ignore_index=True)  # Duplicate and shuffle\n",
    "        return large_df\n",
    "\n",
    "    # Convert back to Spark DataFrame and save as Delta table\n",
    "    large_wine_df = spark.createDataFrame(generate_large_wine_dataset(df, num_copies=100))\n",
    "    output_delta_table = f\"{DA.paths.working_dir}/v01/large_wine_quality_delta\"\n",
    "    large_wine_df.write.format(\"delta\").mode(\"overwrite\").save(output_delta_table)\n",
    "\n",
    "    print(f\"Created large Delta table at {output_delta_table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31842402-e30e-4f34-9e5a-4a1890ad2d71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize DBAcademyHelper\n",
    "DA = DBAcademyHelper() \n",
    "DA.init()          # Performs basic initialization including creating schemas and catalogs\n",
    "DA.create_large_wine_quality_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52a2cba1-c9cb-4180-b05e-0ebe29f8213d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_distributed_predictions_table():\n",
    "    # Define feature columns and assemble them into a vector\n",
    "    feature_columns = [\n",
    "        \"fixed_acidity\", \"volatile_acidity\", \"citric_acid\", \"residual_sugar\", \n",
    "        \"chlorides\", \"free_sulfur_dioxide\", \"total_sulfur_dioxide\", \"density\", \n",
    "        \"pH\", \"sulphates\", \"alcohol\"\n",
    "    ]\n",
    "    \n",
    "    assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "    \n",
    "    # Load the large wine quality table created earlier\n",
    "    table_path = f\"{DA.paths.working_dir}/v01/large_wine_quality_delta\"\n",
    "    df = spark.read.format('delta').load(table_path)\n",
    "\n",
    "    # Assemble features into a vector and split data\n",
    "    df_with_features = assembler.transform(df)\n",
    "    train_df, test_df = df_with_features.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "    # Define and train a simple DecisionTreeRegressor model\n",
    "    dt = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"quality\", maxDepth=5)\n",
    "    pipeline = Pipeline(stages=[dt])\n",
    "    \n",
    "    # Train the model\n",
    "    dt_model = pipeline.fit(train_df)\n",
    "    \n",
    "    # Perform inference on the test data using the trained model\n",
    "    predictions = dt_model.transform(test_df)\n",
    "\n",
    "    # Save predictions to a Delta table\n",
    "    table_name = f\"{DA.catalog_name}.{DA.schema_name}.distributed_predictions_table\"\n",
    "\n",
    "    predictions.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .saveAsTable(table_name)\n",
    "    copy_table_name = f\"{DA.catalog_name}.{DA.schema_name}.predictions_before_optimize\"\n",
    "    predictions.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .saveAsTable(copy_table_name)\n",
    "\n",
    "    print(f\"Created predictions Delta table at {table_name}\")\n",
    "    \n",
    "# Create the distributed predictions table\n",
    "create_distributed_predictions_table()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "Classroom-Setup-3.2",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
