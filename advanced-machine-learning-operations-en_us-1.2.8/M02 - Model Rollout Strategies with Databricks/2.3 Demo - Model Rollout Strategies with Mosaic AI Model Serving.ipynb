{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5748d8aa-9eef-4729-b827-dfaf7f4c097d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86d2168d-eb63-464d-9b44-c9f9f8187933",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Demonstration: Model Rollout Strategies with Mosaic AI Model Serving\n",
    "\n",
    "In this demonstration, we will explore how to perform the rollout strategy known as **A/B testing**. We will also give a brief discussion on how to implement the **Canary Model Rollout Strategy**, a method for releasing an application or service incrementally to a subset of users, as well as Blue Green Rollout. Using Python and Spark, all within the Databricks platform, we will showcase the ease with which we can use Mosaic AI Model Serving and other various tools and features for rollout strategies.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand the fundamentals of A/B testing.\n",
    "- Learn to implement A/B testing frameworks using Spark for scalable data processing.\n",
    "- Explore how to use Mosaic AI model serving to limit traffic and perform controlled experiments.\n",
    "- Gain practical experience with Python and Databricks for real-world testing and deployment workflows.\n",
    "\n",
    "Through this session, you will see how these testing strategies can enhance the reliability and performance of machine learning models and applications in production environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9efac1eb-b0b9-4035-9b44-ae83abb6cb4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## REQUIRED - SELECT CLASSIC COMPUTE\n",
    "Before executing cells in this notebook, please select your classic compute cluster in the lab. Be aware that **Serverless** is enabled by default.\n",
    "Follow these steps to select the classic compute cluster:\n",
    "1. Navigate to the top-right of this notebook and click the drop-down menu to select your cluster. By default, the notebook will use **Serverless**.\n",
    "1. If your cluster is available, select it and continue to the next cell. If the cluster is not shown:\n",
    "   - In the drop-down, select **More**.\n",
    "   - In the **Attach to an existing compute resource** pop-up, select the first drop-down. You will see a unique cluster name in that drop-down. Please select that cluster.\n",
    "\n",
    "**NOTE:** If your cluster has terminated, you might need to restart it in order to select it. To do this:\n",
    "1. Right-click on **Compute** in the left navigation pane and select *Open in new tab*.\n",
    "1. Find the triangle icon to the right of your compute cluster name and click it.\n",
    "1. Wait a few minutes for the cluster to start.\n",
    "1. Once the cluster is running, complete the steps above to select your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00e437c4-c367-43db-84a3-eebb43a6bdee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Requirements\n",
    "\n",
    "Please review the following requirements before starting the lesson:\n",
    "\n",
    "* To run this notebook, you need to use one of the following Databricks runtime(s): **17.3.x-cpu-ml-scala2.13**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e63a7a6-ed9d-4220-8064-3bb2aa504a0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Classroom Setup\n",
    "\n",
    "To get into the lesson, we first need to build some data assets and define some configuration variables required for this demonstration. When running the following cell, the output is hidden so our space isn't cluttered. To view the details of the output, you can hover over the next cell and click the eye icon. \n",
    "\n",
    "The cell after the setup, titled `View Setup Variables`, displays the various variables that were created. You can click the Catalog icon in the notebook space to the right to see that your catalog was created with no data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9129af43-0135-4e05-a874-cf5730830ab8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../Includes/Classroom-Setup-2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01d3ec7d-6662-474c-9b48-e251f4ae42dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Other Conventions:**\n",
    "\n",
    "Throughout this demo, we'll refer to the object `DA`. This object, provided by Databricks Academy, contains variables such as your username, catalog name, schema name, working directory, and dataset locations. Run the code block below to view these details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8250674-3807-4aeb-8d2a-0a56b952fdf2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Username:          {DA.username}\")\n",
    "print(f\"Catalog Name:      {DA.catalog_name}\")\n",
    "print(f\"Schema Name:       {DA.schema_name}\")\n",
    "print(f\"Working Directory: {DA.paths.working_dir}\")\n",
    "print(f\"Dataset Location:  {DA.paths.datasets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f36b2438-edd2-4b57-95f0-4b51818ae5f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Implement A/B Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "029f0e96-dae9-4c7d-92f3-4c48153d937b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create Two Models for Testing\n",
    "\n",
    "Here we will read in our dataset and create two initial models. We will utilize MLflow for model tracking and register them to Unity Catalog and provide aliases to separate the different models. We will imagine that we're asked to determine if one model performs better with including two features: `HvyAlcoholConsump` and `HighChol`. We will label model `A` (our control group) as including all features from our baseline `diabetes` dataset while model `B` will not include these two features. We will provide model `A` with alias `@a` and model `B` with alias `@b` in **schema** under **models**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7b2700f-51ea-4a6d-979a-9293f1c1819c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_registry_uri (\"databricks-uc\")\n",
    "# set the path for mlflow experiment\n",
    "mlflow.set_experiment(f\"/Users/{DA.username}/{DA.schema_name}_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a080809e-d89d-4ac1-b789-86cdc0016193",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.models.signature import infer_signature\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "df = spark.read.format('delta').table('diabetes')\n",
    "training_df = df.toPandas()\n",
    "\n",
    "included_features_list = [c for c in df.columns if c not in [\"Diabetes_binary\",'id']]\n",
    "smaller_included_features_list = [c for c in included_features_list if c not in [\"HvyAlcoholConsump\", \"HighChol\"]]\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_large = training_df[included_features_list]\n",
    "X_small = training_df[smaller_included_features_list]\n",
    "y = training_df[\"Diabetes_binary\"]\n",
    "X_large_train, X_large_test, y_large_train, y_large_test = train_test_split(X_large, y, test_size=0.2, random_state=42)\n",
    "X_small_train = X_large_train.drop(columns=[\"HighChol\", \"HvyAlcoholConsump\"])\n",
    "X_small_test = X_large_test.drop(columns=[\"HighChol\", \"HvyAlcoholConsump\"])\n",
    "y_small_train = y_large_train\n",
    "y_small_test = y_large_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc25285c-8a71-46d7-af70-33fe2f25aa64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "def train_model(X_train,y, alias):\n",
    "    # Start MLflow run\n",
    "    with mlflow.start_run(run_name='mlflow-run') as run:\n",
    "        # Initialize the Random Forest classifier\n",
    "        rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "        # Fit the model on the training data\n",
    "        rf_classifier.fit(X_train, y_large_train)\n",
    "\n",
    "        # Enable autologging\n",
    "        mlflow.sklearn.autolog(log_input_examples=True, silent=True)\n",
    "\n",
    "        # Define the registered model name\n",
    "        registered_model_name = f\"{DA.catalog_name}.{DA.schema_name}.my_model_{DA.unique_name('-')}\"\n",
    "\n",
    "        mlflow.sklearn.log_model(\n",
    "        rf_classifier,\n",
    "        artifact_path = \"model-artifacts\", \n",
    "        input_example=X_train[:3],\n",
    "        signature=infer_signature(X_train, y_large_train)\n",
    "        )\n",
    "\n",
    "        model_uri = f\"runs:/{run.info.run_id}/model-artifacts\"\n",
    "\n",
    "    mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "    # Define the model name \n",
    "    model_name = f\"{DA.catalog_name}.{DA.schema_name}.my_model_{DA.unique_name('-')}\"\n",
    "\n",
    "    # Register the model in the model registry\n",
    "    registered_model = mlflow.register_model(model_uri=model_uri, name=model_name)\n",
    "\n",
    "    # Initialize an MLflow Client\n",
    "    client = MlflowClient()\n",
    "\n",
    "    # Assign an alias\n",
    "    client.set_registered_model_alias(\n",
    "        name= registered_model.name,  # The registered model name\n",
    "        alias=alias,  # The alias representing the dev environment\n",
    "        version=registered_model.version  # The version of the model you want to move to \"dev\"\n",
    "    )\n",
    "\n",
    "train_model(X_large_train,y_large_train, 'a')\n",
    "train_model(X_small_train,y_small_train, 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d540dac4-8d15-4175-a6f7-b5a1304ad5f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Mosaic AI Model Serving\n",
    "\n",
    "Next, we need to determine how to deploy these models and how to direct traffic. Databricks Mosaic AI Model Serving makes this really simple to do. Let's setup a model serving endpoint and direct traffic to point 50% to one model and 50% to the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d196b6c-3170-4bad-9e21-d06b552bf758",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "\n",
    "# Initialize the MLflow Client\n",
    "client = MlflowClient()\n",
    "\n",
    "# Define the model name and alias\n",
    "model_name = f\"{DA.catalog_name}.{DA.schema_name}.my_model_{DA.unique_name('-')}\" # Replace with your actual model name\n",
    "alias_a = \"a\" \n",
    "alias_b = \"b\"\n",
    "\n",
    "# Get the model version by alias\n",
    "model_a_version= client.get_model_version_by_alias(model_name, alias_a).version\n",
    "model_b_version = client.get_model_version_by_alias(model_name, alias_b).version\n",
    "\n",
    "# Print the model version\n",
    "print(f\"Version for model a: {model_a_version}\")\n",
    "print(f\"Version for model b: {model_b_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d87323a-fe78-481f-b3e8-fc78bc39ce36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "try:\n",
    "    # Initialize the workspace client\n",
    "    workspace = WorkspaceClient()\n",
    "\n",
    "    # Delete the serving endpoint\n",
    "    workspace.serving_endpoints.delete(name=f\"M02-endpoint_{DA.schema_name}\")\n",
    "except:\n",
    "    print(\"Endpoint does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93627796-ecfd-4853-8ad5-3dff6830a863",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.deployments import get_deploy_client\n",
    "import time\n",
    "\n",
    "client = get_deploy_client(\"databricks\")\n",
    "endpoint_name = f\"M02-endpoint_{DA.schema_name}\"\n",
    "spark.sql(f'use catalog {DA.catalog_name}')\n",
    "spark.sql(f'use schema {DA.schema_name}')\n",
    "\n",
    "def wait_for_endpoint(endpoint_name, timeout=1200, interval=200):\n",
    "    start_time = time.time()\n",
    "    while time.time() - start_time < timeout:\n",
    "        try:\n",
    "            endpoint_status = client.get_endpoint(endpoint_name)\n",
    "            if endpoint_status[\"state\"][\"ready\"]:\n",
    "                print(f\"Endpoint '{endpoint_name}' is ready.\")\n",
    "                return\n",
    "        except Exception as e:\n",
    "            if \"RESOURCE_DOES_NOT_EXIST\" in str(e):\n",
    "                print(f\"Endpoint '{endpoint_name}' does not exist yet.\")\n",
    "            else:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "        time.sleep(interval)\n",
    "    print(f\"Timeout: Endpoint '{endpoint_name}' is not ready after {timeout} seconds.\")\n",
    "# Check if the endpoint already exists\n",
    "try:\n",
    "    # Attempt to get the endpoint\n",
    "    existing_endpoint = client.get_endpoint(endpoint_name)\n",
    "    print(f\"Endpoint '{endpoint_name}' already exists.\")\n",
    "except Exception as e:\n",
    "    # If not found, create the endpoint\n",
    "    if \"RESOURCE_DOES_NOT_EXIST\" in str(e):\n",
    "        print(f\"Creating a new endpoint: {endpoint_name}\")\n",
    "        endpoint = client.create_endpoint(\n",
    "            name=endpoint_name,\n",
    "            config={\n",
    "                \"served_entities\": [\n",
    "                    {\n",
    "                        \"name\": \"my-model-a\",\n",
    "                        \"entity_name\": model_name,\n",
    "                        \"entity_version\": model_a_version,\n",
    "                        \"workload_size\": \"Small\",\n",
    "                        \"scale_to_zero_enabled\": True\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"my-model-b\",\n",
    "                        \"entity_name\": model_name,\n",
    "                        \"entity_version\": model_b_version,\n",
    "                        \"workload_size\": \"Small\",\n",
    "                        \"scale_to_zero_enabled\": True\n",
    "                    }\n",
    "                ],\n",
    "                \"traffic_config\": {\n",
    "                    \"routes\": [\n",
    "                        {\n",
    "                            \"served_model_name\": \"my-model-a\",\n",
    "                            \"traffic_percentage\": 50\n",
    "                        },\n",
    "                        {\n",
    "                            \"served_model_name\": \"my-model-b\",\n",
    "                            \"traffic_percentage\": 50\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        wait_for_endpoint(endpoint_name)\n",
    "    else:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88a4ed1b-9a44-40a6-844e-4283d7052710",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Querying the endpoint\n",
    "\n",
    "We now simulate how you perform A/B testing with Mosaic AI Model Serving. Recall that model B has two fewer features than model A. So, when we send in the query, we want to make sure that we're looking at the larger test set instead of the smaller one. The endpoint will ignore features that don't apply to model B and will use all of the features that apply to model A. \n",
    "\n",
    "In this step we will inference on batches of the test dataset while monitoring which model is being served so we can see the split. \n",
    "\n",
    "**Warning: It may take a few moments for your endpoint to deploy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3897ba91-4578-41a8-85da-7096a01d0ceb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"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\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksViewfabd6b9\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksViewfabd6b9\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksViewfabd6b9\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksViewfabd6b9) SELECT `model_served`,AVG(`prediction`) `column_2faa7eb3147` FROM q GROUP BY `model_served`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksViewfabd6b9\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "model_served",
             "id": "column_2faa7eb3146"
            },
            "y": [
             {
              "column": "prediction",
              "id": "column_2faa7eb3147",
              "transform": "AVG"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "column",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_2faa7eb3147": {
             "name": "prediction",
             "type": "column",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": true,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {},
       "nuid": "206144b1-9065-43f4-9b49-88caa6dcf00c",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 20.0,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "model_served",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "model_served",
           "type": "column"
          },
          {
           "alias": "column_2faa7eb3147",
           "args": [
            {
             "column": "prediction",
             "type": "column"
            }
           ],
           "function": "AVG",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from mlflow.deployments import get_deploy_client\n",
    "\n",
    "# Initialize Databricks client\n",
    "client = get_deploy_client(\"databricks\")\n",
    "w = WorkspaceClient()\n",
    "\n",
    "# Function to wait for model serving endpoint to be fully READY\n",
    "def wait_for_fully_ready_endpoint(endpoint_name, timeout=1800, interval=200):\n",
    "    \"\"\"\n",
    "    Waits until the endpoint is fully READY, checking its status every `interval` seconds.\n",
    "    \n",
    "    Args:\n",
    "        endpoint_name (str): The name of the endpoint.\n",
    "        timeout (int): Maximum time (seconds) to wait.\n",
    "        interval (int): Time (seconds) between checks.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the endpoint is READY, False if timeout occurs.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    while time.time() - start_time < timeout:\n",
    "        try:\n",
    "            endpoint_status = client.get_endpoint(endpoint_name)\n",
    "            state = endpoint_status.get(\"state\", {})\n",
    "\n",
    "            ready_state = state.get(\"ready\", \"NOT_READY\")\n",
    "            config_update_state = state.get(\"config_update\", \"IN_PROGRESS\")\n",
    "\n",
    "            print(f\"Waiting for endpoint '{endpoint_name}' to be READY... [Status: {ready_state}, Config: {config_update_state}]\")\n",
    "\n",
    "            if ready_state == \"READY\" and config_update_state == \"NOT_UPDATING\":\n",
    "                print(f\"Endpoint '{endpoint_name}' is now fully READY.\")\n",
    "                return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error checking endpoint status: {e}\")\n",
    "\n",
    "        time.sleep(interval)\n",
    "\n",
    "    print(f\"Timeout: Endpoint '{endpoint_name}' was not fully ready after {timeout} seconds.\")\n",
    "    return False\n",
    "\n",
    "# Ensure the endpoint is fully ready before querying\n",
    "if wait_for_fully_ready_endpoint(endpoint_name):\n",
    "    print(f\"Endpoint '{endpoint_name}' is fully ready. Proceeding with inference.\")\n",
    "else:\n",
    "    raise RuntimeError(f\" Endpoint '{endpoint_name}' is not fully available. Please check deployment.\")\n",
    "\n",
    "# Initialize an empty DataFrame to store results\n",
    "results_df = pd.DataFrame(columns=[\"prediction\", \"model_served\"])\n",
    "requests = X_large_test.reset_index()\n",
    "\n",
    "batch_size = 10\n",
    "number_of_batches = 5\n",
    "\n",
    "# Perform inference on batches of the test dataset\n",
    "for batch_num in range(number_of_batches):\n",
    "    try:\n",
    "        # Fetch the batch of requests\n",
    "        batch = payload(requests[requests.index // batch_size == batch_num].to_dict(orient='split'))\n",
    "        \n",
    "        # Query the serving endpoint\n",
    "        query_response = w.serving_endpoints.query(name=endpoint_name, dataframe_split=batch)\n",
    "\n",
    "        # Print batch details\n",
    "        print(f\"Batch {batch_num + 1} response:\")\n",
    "        print(batch)\n",
    "        print(query_response)\n",
    "\n",
    "        # Extract predictions and model served information\n",
    "        batch_results = pd.DataFrame({\n",
    "            \"prediction\": query_response.predictions,\n",
    "            \"model_served\": query_response.served_model_name\n",
    "        })\n",
    "\n",
    "        # Append batch results to the main DataFrame\n",
    "        results_df = pd.concat([results_df, batch_results], ignore_index=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {batch_num + 1}: {e}\")\n",
    "        continue  # Skip to the next batch\n",
    "\n",
    "# Display the final results DataFrame\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50856968-d490-44c5-81ed-0b66349c77f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### View Data about the Served Model\n",
    "In addition to the frequency of the model served, we can view latency using the UI. Navigate to the model serving endpoint in **Serving** and scroll down to view Metrics. Here you will find Latency, Request Rate, Request Error, CPU Usage, Memory Usage, and Provisioned Concurrency. All of these should be taken into account when making a determination of rolling out a new model. \n",
    "\n",
    "In the **Events** tab you will see the **Timestamp** along with **Event type**, **Served entity name**, and **message**. This can be useful for transparency in rolling out the model to determine how long it takes for any particular event. \n",
    "\n",
    "Additionally, you can view the **Logs** of the serving model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f65a829-d76d-45fc-a422-fc8fad396a3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Metric Tracking\n",
    "\n",
    "Now that we have established our different models as well as setup our hypothesis, let's take a moment to establish which metrics we will be tracking. Since we are using a random forest classifier, some important metrics include F1-score, precision, recall, accuracy, and AUC-ROC. The table below summarizes the metric, its use case and focus area. We will not go into analysis here, as that is covered in a separate demonstration. \n",
    "\n",
    "### Suggested Tracking Plan\n",
    "\n",
    "| **Metric**              | **Use Case**                                  | **Focus Area**                  |\n",
    "|--------------------------|-----------------------------------------------|----------------------------------|\n",
    "| **F1-Score**            | Overall balance between precision and recall | Primary metric for A/B testing  |\n",
    "| **Precision and Recall** | Insights into specific model behaviors       | For deeper performance insights |\n",
    "| **AUC-ROC or PR AUC**   | Discrimination ability and imbalance focus   | Secondary evaluation            |\n",
    "| **Log Loss**            | Prediction confidence                        | Confidence assessment           |\n",
    "| **Feature Importance**  | New feature contribution                     | Validate feature utility        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cccf4f5-5b47-4803-8fe1-e7c74bd25ebd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Additional Rollout Strategies\n",
    "\n",
    "We close this demo with describing two additional common rollout strategies that we will go into due to time constraints. However, it is worth describing how Mosaic AI can still solve these problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff5ebb98-1d7b-47bb-ae39-d0b3a0586a3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Adaptation to Blue-Green Rollout\n",
    "\n",
    "Using Mosaic AI Model Serving makes it effortless to switch between different served models. Recall that **Blue-green testing** is a deployment strategy that minimizes the downtime to reduce the risk during the release of new features or updates to applications. \n",
    "\n",
    "**Case 1: Zero Downtime**\n",
    "\n",
    "If we need 0 downtime, we can simply have two endpoints deployed and expose the application to the correct API and immediately delete the old model serving endpoint. We would maintain both versions of the code but only delete the older one once the new is in use. \n",
    "\n",
    "**Case 2: A Few Minutes Downtime**\n",
    "\n",
    "If we are allowed to have a few minutes of downtime, we can use the same model serving endpoint and update the version being served by using the following code. Note that this may take a few minutes to update, but we only have a single model serving endpoint deployed in this case. \n",
    "\n",
    "To summarize, with zero downtime, we must maintain two separate model serving endpoints, which can be costly. If we allow for a few minutes of downtime, then we only have to maintain a single endpoint and simply perform the switch when we are ready. In the latter case, we don't need to maintain two endpoints or worry about cleaning up resources. With Mosaic AI Model Serving, the previous state of the endpoint is always running until the update to the new state is complete. This means the only element you have to adjust your rollout for is the time it takes to update to the new endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "347f7183-68b9-439a-9ce7-58a2d78bc8cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Adaptation to Canary Rollout\n",
    "\n",
    "Using Mosaic AI Model Serving, you can perform a gradual rollout by controlling the traffic directed to each model version. Unlike in A/B testing, where we might use a fixed 50/50 split to compare model versions, a canary rollout involves progressively increasing the traffic to the new model. For example, you could start with a 10/90 split (10% to the new model and 90% to the current model), then adjust to a 30/70 split, and so on, until the new model handles 100% of the traffic.\n",
    "\n",
    "This gradual approach ensures the new model can be validated at scale without sacrificing uptime. Additionally, unlike the blue-green rollout strategy, a canary rollout does not require maintaining separate endpoints. Instead, traffic routing is dynamically adjusted, making it a cost-effective and low-risk strategy for rolling out updates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7105efc6-6d26-4253-ad68-b1109e070aeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this demonstration you learned about how to utilize MLflow along with Unity Catalog and Mosaic AI to enforce various rollout strategies with an emphasis on A/B testing. In addition, you learned how providing an alias can help keep track of which model you wish to rollout or test against. Finally, you learned how Mosaic AI allows for split traffic to make rollout strategies like blue-green and canary painless by simply updating the model serving endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9471ec4b-3170-4bc6-9e66-40d321986814",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2026 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2.3 Demo - Model Rollout Strategies with Mosaic AI Model Serving",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
