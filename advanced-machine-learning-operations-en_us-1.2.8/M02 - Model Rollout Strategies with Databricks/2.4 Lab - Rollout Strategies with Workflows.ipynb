{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7bf5a4f-fcf4-47a4-9f99-28133b6ce4e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c0a0e70-034d-4eb0-8b93-5d6c23ce4e1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Lab: Rollout Strategies with Workflows\n",
    "\n",
    "In this lab, you will do the following:\n",
    "1. Bring in a table from Databricks Marketplace.\n",
    "1. Perform feature engineering and store the table in Databricks Feature Store.\n",
    "1. Perform validation test to check for missing values, confirm the schema, and check for non-negative values. \n",
    "1. You will also check that normalization was carried out correctly. \n",
    "1. Finally, you will train and serve 2 models while directing traffic to one model 40% of the time and to the other model 60% of the time. \n",
    "\n",
    "**Learning Objectives**\n",
    "\n",
    "By the end of this lab you will be able to\n",
    "- Demonstrate knowledge of how to setup integration tests with Databricks Workflows.\n",
    "- Demonstrate knowledge of how to configure a model serving endpoint for serving an uneven traffic distribution for 2 models. \n",
    "- Demonstrate an understanding of working with MLflow and Unity Catalog for testing rollout strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "caf404ff-5eea-4a09-bae3-e1f03de243a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## REQUIRED - SELECT CLASSIC COMPUTE\n",
    "Before executing cells in this notebook, please select your classic compute cluster in the lab. Be aware that **Serverless** is enabled by default.\n",
    "Follow these steps to select the classic compute cluster:\n",
    "1. Navigate to the top-right of this notebook and click the drop-down menu to select your cluster. By default, the notebook will use **Serverless**.\n",
    "1. If your cluster is available, select it and continue to the next cell. If the cluster is not shown:\n",
    "   - In the drop-down, select **More**.\n",
    "   - In the **Attach to an existing compute resource** pop-up, select the first drop-down. You will see a unique cluster name in that drop-down. Please select that cluster.\n",
    "\n",
    "**NOTE:** If your cluster has terminated, you might need to restart it in order to select it. To do this:\n",
    "1. Right-click on **Compute** in the left navigation pane and select *Open in new tab*.\n",
    "1. Find the triangle icon to the right of your compute cluster name and click it.\n",
    "1. Wait a few minutes for the cluster to start.\n",
    "1. Once the cluster is running, complete the steps above to select your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2735102f-1233-4dea-bb1a-50fe917c1878",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Requirements\n",
    "\n",
    "Please review the following requirements before starting the lesson:\n",
    "\n",
    "* To run this notebook, you need to use one of the following Databricks runtime(s): **17.3.x-cpu-ml-scala2.13**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa90d3e5-2409-473e-8d96-c81bd2d97c33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Classroom Setup\n",
    "\n",
    "To get into the lesson, you first need to build some data assets and define some configuration variables required for this demonstration. When running the following cell, the output is hidden so our space isn't cluttered. To view the details of the output, you can hover over the next cell and click the eye icon. \n",
    "\n",
    "The cell after the setup, titled `View Setup Variables`, displays the various variables that were created. You can click the Catalog icon in the notebook space to the right to see that your catalog was created with no data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a334f7b-c804-45ab-a27b-e4e453c88251",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../Includes/Classroom-Setup-2.Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb2526dc-7599-4427-a480-e6234efeb896",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The following variables will be useful for you to configure your various parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c15ada6-dfa1-435c-8fbc-751aedb6287d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Username:          {DA.username}\")\n",
    "print(f\"Catalog Name:      {DA.catalog_name}\")\n",
    "print(f\"Schema Name:       {DA.schema_name}\")\n",
    "print(f\"Working Directory: {DA.paths.working_dir}\")\n",
    "print(f\"Dataset Location:  {DA.paths.datasets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af077ae9-edf9-4ca9-b7dc-33f48ef33317",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Workflow Setup\n",
    "Here you will setup an integration test using Databrick Workflows. There will be a total of 5 Workflow notebooks that you will need to **fill out** as a part of completing this lab. They are located in the folder title **2.4 Lab - Model Training Pipeline**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d6cff14-9df5-4069-b8cd-5011db626ef0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Review of How to Attach Workflow Notebooks\n",
    "\n",
    "> **For Experienced Users:** If you are already familiar with setting up workflows, you can skip the detailed steps below and proceed directly to setting up the workflow.\n",
    "> \n",
    "> **For New Users or Those Needing a Refresher:** Follow the step-by-step instructions below to set up your workflow.\n",
    "\n",
    "\n",
    "1. Navigate to **Jobs & Pipelines**:\n",
    "   - Open the [**Jobs & Pipelines**](/jobs) page (also accessible from the left sidebar).\n",
    "1. Click on **Create** and select **Job** from the dropdown in the upper-right corner of the page.\n",
    "\n",
    "1. Set the Job name to ***Rollout Strategies with Workflow*** or something similar for easy identification.\n",
    "\n",
    "1. **Set Up the Task**:\n",
    "   - Select `Notebook`.\n",
    "   - Select **Notebook** at the top of the menu that appears.\n",
    "   - Provide a **Task Name** (e.g., `Silver_to_Feature_Store`).\n",
    "   - Set the **Type** to `Notebook`.\n",
    "   - For **Source**, select `Workspace`.\n",
    "   - In **Path**, navigate to the second notebook.\n",
    "\n",
    "1. **Configure Compute**:\n",
    "   - In the **Compute** section, select the cluster you have been working on.\n",
    "\n",
    "1. **Configure Dependencies**:\n",
    "   - In the **Depends On** section, notice that your previous task is automatically selected. Leave this as is.\n",
    "\n",
    "1. **Add Parameters**\n",
    "\n",
    "1. Click **Save task**\n",
    "\n",
    "1. in the **Tasks** grid, click **+ Add task**. Repeat the steps till third task for the third notebook.\n",
    "\n",
    "1. **Create and Run the Task**:\n",
    "   - Once all details and parameters are entered, click on **Create Task**.\n",
    "   - After creating the task, click **Run Now** to execute it.\n",
    "\n",
    "Wait a moment for the pipeline to run and validate that the job was successful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d734fd8-4f5f-4aac-9230-defd4d2daff6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Step 1: Set Up Workflow Notebooks  \n",
    "\n",
    "The first step is to setup notebooks that will be used for Workflows. All Workflows notebooks can be found in the folder labeled **2.4 Lab - Model Training Pipeline**.\n",
    "\n",
    "For each notebook below, navigate to **`2.4 Lab - Model Training Pipeline`**, open the specified notebook, and fill in the necessary code. **Widgets have been preconfigured**, so you only need to focus on implementing the required logic.  \n",
    "\n",
    "\n",
    "1. Configure Notebook: **\"01 Silver to Feature Store\"** \n",
    "- Enter the task name of your choice, or alternatively, use the name of the notebook. \n",
    "- Navigate to **`2.4 Lab - Model Training Pipeline`** and open **`01 - Silver to Feature Store`**.  \n",
    "- Fill in the required code where necessary.  \n",
    "- Use the following parameters when setting up the Workflow:  \n",
    "\n",
    "```\n",
    "{\n",
    "  \"catalog\": \"dbacademy\",\n",
    "  \"column\": \"Age\",\n",
    "  \"primary_key\": \"id\",\n",
    "  \"schema\": \"<your_schema>\",\n",
    "  \"silver_table_name\": \"diabetes\",\n",
    "  \"target_column\": \"Diabetes_binary\"\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "2. Configure Notebook: **\"02 Data Validation Tests\"**  \n",
    "- Enter the task name of your choice, or alternatively, use the name of the notebook.\n",
    "- Navigate to **`2.4 Lab - Model Training Pipeline`** and open **`02 - Data Validation Tests`**.  \n",
    "- Fill in the required code where necessary.  \n",
    "- Use the following parameters when setting up the Workflow:  \n",
    "\n",
    "```\n",
    "{\n",
    "  \"catalog\": \"dbacademy\",\n",
    "  \"schema\": \"<your_schema>\",\n",
    "  \"silver_table_name\": \"diabetes\"\n",
    "}\n",
    "```\n",
    "\n",
    "3. Configure Notebook: **\"03 Normalization Validation\"**  \n",
    "- Enter the task name of your choice, or alternatively, use the name of the notebook.\n",
    "- Navigate to **`2.4 Lab - Model Training Pipeline`** and open **`03 - Normalization Validation`**.  \n",
    "- Fill in the required code where necessary.  \n",
    "- Use the following parameters when setting up the Workflow:  \n",
    "\n",
    "```\n",
    "{\n",
    "  \"catalog\": \"dbacademy\",\n",
    "  \"schema\": \"<your_schema>\",\n",
    "  \"normalized_column\": \"Age\",\n",
    "  \"silver_table_name\": \"diabetes\"\n",
    "}\n",
    "```\n",
    "\n",
    "4. Configure Notebook: **\"04 Train Models on Validated Features\"**  \n",
    "- Enter the task name of your choice, or alternatively, use the name of the notebook.\n",
    "- Navigate to **`2.4 Lab - Model Training Pipeline`** and open **`04 - Train Models on Validated Features`**.  \n",
    "- Fill in the required code where necessary.  \n",
    "- Use the following parameters when setting up the Workflow:  \n",
    "\n",
    "```\n",
    "{\n",
    "  \"catalog\": \"dbacademy\",\n",
    "  \"delete_column\": \"BMI\",\n",
    "  \"primary_key\": \"id\",\n",
    "  \"schema\": \"<your_schema>\",\n",
    "  \"silver_table_name\": \"diabetes\",\n",
    "  \"target_column\": \"Diabetes_binary\"\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "5. Configure Notebook: **\"05 Serve the Model\"**  \n",
    "- Enter the task name of your choice, or alternatively, use the name of the notebook.\n",
    "- Navigate to **`2.4 Lab - Model Training Pipeline`** and open **`05 - Serve the Model`**.  \n",
    "- Fill in the required code where necessary.  \n",
    "- Use the following parameters when setting up the Workflow:  \n",
    "\n",
    "```\n",
    "{\n",
    "  \"catalog\": \"dbacademy\",\n",
    "  \"schema\": \"<your_schema>\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2a434c5-4045-42e2-ae6f-ec48f1b5488a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 2: Individual Notebook Testing\n",
    "\n",
    "After you have configured each of the notebooks, you should run them individually to squash any outstanding bugs. Waiting for an entire workflow to kick off just to have the final notebook fail can be a huge waste of time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "828a8508-23b3-4051-b7dc-befb84e2223f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 3: Chain the notebooks together to complete the model serving workflow. \n",
    "\n",
    "See the notes before Step 1 if you need assistance doing this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42189642-465f-4b65-ac52-bfb140dfdf2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this lab, you created a workflow that demonstrates common testing strategies with a goal of training 2 models and serving them with Mosaic AI Model Serving. You learned how integral test strategies are the role MLflow and Unity Catalog play in accomplishing tasks involving testing. Finally, you demonstrated knowledge of splitting traffic in a 40/60 -split by configuring deployments with Mosaic AI Model Serving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b2de4d4-359b-426c-80fc-edb809c115d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2026 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "2.4 Lab - Rollout Strategies with Workflows",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
