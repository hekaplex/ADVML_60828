{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6edf6d2-396b-41bf-94d3-071d9ddbbf9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f91984ef-935c-4b63-b12c-9472d13d4ead",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Demonstration - Common Testing Strategies\n",
    "\n",
    "In this demonstration, you will investigate common pipeline testing strategies for data science and machine learning. In addition, you will be given an introduction to **unittest**, a common testing framework. You will gain a new perspective of MLflow as an integral tool for proper model testing and important to modern MLOps pipelines. \n",
    "\n",
    "\n",
    "\n",
    "**Learning Objectives**\n",
    "\n",
    "By the end of this demonstration, you will be able to do the following:\n",
    "\n",
    "- Understand the differences between different pipeline tests and how to build helper functions to validate the following types of tests:\n",
    "    - Data Validation\n",
    "    - Data Transformation\n",
    "    - Model Integration\n",
    "    - Modeling Functions\n",
    "        - Testing model functions will utilize MLflow and Unity Catalog for comprehensive versioning and lineage. \n",
    "- Understand **unittest** as a comprehensive testing framework \n",
    "\n",
    "**ðŸš¨Warning: Some of the cells are meant to fail for demonstration purposes.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9845db00-4c40-4bea-a933-df1ea08fa3cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## REQUIRED - SELECT CLASSIC COMPUTE\n",
    "Before executing cells in this notebook, please select your classic compute cluster in the lab. Be aware that **Serverless** is enabled by default.\n",
    "Follow these steps to select the classic compute cluster:\n",
    "1. Navigate to the top-right of this notebook and click the drop-down menu to select your cluster. By default, the notebook will use **Serverless**.\n",
    "1. If your cluster is available, select it and continue to the next cell. If the cluster is not shown:\n",
    "   - In the drop-down, select **More**.\n",
    "   - In the **Attach to an existing compute resource** pop-up, select the first drop-down. You will see a unique cluster name in that drop-down. Please select that cluster.\n",
    "\n",
    "**NOTE:** If your cluster has terminated, you might need to restart it in order to select it. To do this:\n",
    "1. Right-click on **Compute** in the left navigation pane and select *Open in new tab*.\n",
    "1. Find the triangle icon to the right of your compute cluster name and click it.\n",
    "1. Wait a few minutes for the cluster to start.\n",
    "1. Once the cluster is running, complete the steps above to select your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df590d8c-3774-4af8-ae4e-3c6e43e79021",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Requirements\n",
    "\n",
    "Please review the following requirements before starting the lesson:\n",
    "\n",
    "* To run this notebook, you need to use one of the following Databricks runtime(s): **17.3.x-cpu-ml-scala2.13**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ad0a2c9-53ac-4e02-a169-84bbb663491a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Classroom Setup\n",
    "\n",
    "To get into the lesson, we first need to build some data assets and define some configuration variables required for this demonstration. When running the following cell, the output is hidden so our space isn't cluttered. To view the details of the output, you can hover over the next cell and click the eye icon. \n",
    "\n",
    "The cell after the setup, titled `View Setup Variables`, displays the various variables that were created. You can click the Catalog icon in the notebook space to the right to see that your catalog was created with no data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a49044d7-617e-4108-90b9-229a4a8b1d7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../Includes/Classroom-Setup-2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "245a36a1-f4be-431b-bf55-1ffa673b7dec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Other Conventions:**\n",
    "\n",
    "Throughout this demo, we'll refer to the object `DA`. This object, provided by Databricks Academy, contains variables such as your username, catalog name, schema name, working directory, and dataset locations. Run the code block below to view these details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1baedde-1c47-487b-8f49-ecc0f12fd834",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Username:          {DA.username}\")\n",
    "print(f\"Catalog Name:      {DA.catalog_name}\")\n",
    "print(f\"Schema Name:       {DA.schema_name}\")\n",
    "print(f\"Working Directory: {DA.paths.working_dir}\")\n",
    "print(f\"Dataset Location:  {DA.paths.datasets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acc97734-581a-4f84-85fc-44e7050e793d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Further Preparation - Train, Register, and Serve ML model\n",
    "\n",
    "For testing that our model is behaving as intended, we will train and package our model with MLflow, register it to Unity Catalog, serve the model using Mosaic AI Model Serving. \n",
    "\n",
    "**Warning: It will take a few minutes to setup the Model Serving Endpoint.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6dac0571-1335-448e-a17d-e205587ec976",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "# Modify the registry uri to point to Unity Catalog\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# Define the model name \n",
    "model_name = f\"{DA.catalog_name}.{DA.schema_name}.{DA.username}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c86309db-bdb2-4d13-8359-57ce02e0321c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "df = spark.read.format('delta').table('diabetes')\n",
    "training_df = df.toPandas()\n",
    "\n",
    "X = training_df.drop([\"id\", \"Diabetes_binary\"], axis=1)\n",
    "y = training_df[\"Diabetes_binary\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# set the path for mlflow experiment\n",
    "mlflow.set_experiment(f\"/Users/{DA.username}/{DA.username}_model\")\n",
    "\n",
    "with mlflow.start_run(run_name = 'mlflow-run') as run:  \n",
    "    # Initialize the Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "    # Enable automatic logging of input samples, metrics, parameters, and models\n",
    "    mlflow.sklearn.autolog(\n",
    "        log_input_examples = True,\n",
    "        silent = True\n",
    "    )\n",
    "        \n",
    "    mlflow.sklearn.log_model(\n",
    "        rf_classifier,\n",
    "        artifact_path = \"model-artifacts\", \n",
    "        input_example=X_train[:3],\n",
    "        signature=infer_signature(X_train, y_train)\n",
    "    )\n",
    "\n",
    "    model_uri = f\"runs:/{run.info.run_id}/model-artifacts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3207e28d-e2e2-4fa7-a9ac-ad10a6bd2479",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Register the model in the model registry\n",
    "registered_model = mlflow.register_model(model_uri=model_uri, name=f\"{DA.catalog_name}.{DA.schema_name}.testing_strats_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e338801b-1c05-454a-b6d7-637a1611e1d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "try:\n",
    "    # Initialize the workspace client\n",
    "    workspace = WorkspaceClient()\n",
    "\n",
    "    # Delete the serving endpoint\n",
    "    workspace.serving_endpoints.delete(name=f\"M02-endpoint_{DA.schema_name}\")\n",
    "    print('Deleted Endpoint M02-endpoint')\n",
    "except:\n",
    "    print(f\"Endpoint M02-endpoint_{DA.schema_name} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0b771e5-d5ef-4186-953a-2bda1d4fbc45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.deployments import get_deploy_client\n",
    "\n",
    "client = get_deploy_client(\"databricks\")\n",
    "endpoint_name = f\"M02-endpoint_{DA.schema_name}\"\n",
    "endpoint_name = endpoint_name.replace(\"@databricks.com\", \"\").replace('.', '-')\n",
    "spark.sql(f'use catalog {DA.catalog_name}')\n",
    "spark.sql(f'use schema {DA.schema_name}')\n",
    "# Check if the endpoint already exists\n",
    "try:\n",
    "    # Attempt to get the endpoint\n",
    "    existing_endpoint = client.get_endpoint(endpoint_name)\n",
    "    print(f\"Endpoint '{endpoint_name}' already exists.\")\n",
    "except Exception as e:\n",
    "    # If not found, create the endpoint\n",
    "    if \"RESOURCE_DOES_NOT_EXIST\" in str(e):\n",
    "        print(f\"Creating a new endpoint: {endpoint_name}\")\n",
    "        endpoint = client.create_endpoint(\n",
    "            name=endpoint_name,\n",
    "            config={\n",
    "                \"served_entities\": [\n",
    "                    {\n",
    "                        \"name\": \"strats-model\",\n",
    "                        \"entity_name\": f\"{DA.catalog_name}.{DA.schema_name}.testing_strats_model\",\n",
    "                        \"entity_version\": 1,\n",
    "                        \"workload_size\": \"Small\",\n",
    "                        \"scale_to_zero_enabled\": True\n",
    "                    },\n",
    "                ],\n",
    "                \"traffic_config\": {\n",
    "                    \"routes\": [\n",
    "                        {\n",
    "                            \"served_model_name\": \"strats-model\",\n",
    "                            \"traffic_percentage\": 100\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d261ce5f-f022-4f72-98f2-22f453b4db78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Common ML Pipeline Testing\n",
    "\n",
    "Here we will go over common ML pipeline testing paradigms that can be used to ensure robust and reliable ML models by testing various aspects of the ML pipeline. We will focus on the following:\n",
    "1. Data Validation - data quality checks, expected pattern checks, and custom business logic are enforced.\n",
    "1. Data Transformations - apply data transformations like normalization and encoding for feature engineering tasks.\n",
    "1. Modeling functions - unit and integration tests are used to test individual component interactions as well as overall end-to-end testing.\n",
    "1. Model Integration - CI/CD integration along with MLOps workflows to enable long-term efficiency of ML systems\n",
    "\n",
    "When exploring each of these components of testing, we will provide helper functions. It should be noted that this is not a comprehensive dive into each of these topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4bde368-d32f-41c9-b102-55b0e9df8d7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data Validation\n",
    "Data Validation for ML Pipeline Testing involves ensuring that the input, intermediate, and output data in a machine learning pipeline meet expected quality, structure, and distribution standards. It is a critical step to verify that the data being processed in an ML pipeline aligns with the assumptions made during model development, ensuring the reliability and correctness of the pipeline. Here we will verify our dataframe schema, that no values are missing, and that non-negative values do not exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27169c12-88db-4957-96f4-7291b4aeb22e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Define Helper Functions\n",
    "\n",
    "These functions provide validation checks for (PySpark) DataFrames to ensure data quality and consistency. \n",
    "\n",
    "- `validate_schema` ensures the schema matches an expected definition.\n",
    "- `validate_no_missing_values` checks for and reports any missing (null) values in the DataFrame.\n",
    "- `validate_binary_column` confirms that a specified column contains only binary values (0 or 1).\n",
    "- `validate_double_column` verifies that a specific columnâ€™s data type is double.\n",
    "- `validate_non_negative_values` ensures that all columns in the DataFrame contain only non-negative values. \n",
    "\n",
    "Overall, these function help to enforce data integrity for downstream machine learning or analytical tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f79adb7d-6325-4099-bee3-4914b6537e1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def validate_schema(df, expected_schema):\n",
    "    \"\"\"\n",
    "    Validates whether the schema of the given DataFrame matches the expected schema.\n",
    "\n",
    "    Parameters:\n",
    "    - df: The PySpark DataFrame to check.\n",
    "    - expected_schema: The expected schema (StructType).\n",
    "\n",
    "    Uses:\n",
    "    - AssertionError if the schema does not match.\n",
    "    \"\"\"\n",
    "\n",
    "    actual_schema = df.schema\n",
    "    assert actual_schema == expected_schema, (\n",
    "        f\"Schema validation failed.\\n\"\n",
    "        f\"Expected schema: {expected_schema}\\n\"\n",
    "        f\"Actual schema: {actual_schema}\"\n",
    "    )\n",
    "    print(\"Schema validation passed!\")\n",
    "\n",
    "def validate_no_missing_values(df):\n",
    "    \"\"\"\n",
    "    Validates that the given PySpark DataFrame contains no missing (null) values.\n",
    "\n",
    "    Parameters:\n",
    "    - df: The PySpark DataFrame to check.\n",
    "\n",
    "    Uses:\n",
    "    - AssertionError if missing values are found.\n",
    "    \"\"\"\n",
    "    from pyspark.sql.functions import col, sum\n",
    "\n",
    "    missing_values = df.agg(*[\n",
    "        sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns\n",
    "    ]).collect()[0].asDict()\n",
    "\n",
    "    missing_columns = {col: missing_values[col] for col in df.columns if missing_values[col] > 0}\n",
    "\n",
    "    assert not missing_columns, (\n",
    "        f\"Missing values found in the following columns: {missing_columns}\"\n",
    "    )\n",
    "    print(\"No missing values detected!\")\n",
    "\n",
    "def validate_binary_column(df, column_name):\n",
    "    \"\"\"\n",
    "    Validates that the specified column in the DataFrame contains only binary values (0 or 1).\n",
    "\n",
    "    Parameters:\n",
    "    - df: The PySpark DataFrame to check.\n",
    "    - column_name: The name of the column to validate.\n",
    "\n",
    "    Uses:\n",
    "    - AssertionError if the column contains non-binary values.\n",
    "    \"\"\"\n",
    "    # Find distinct values in the column\n",
    "    distinct_values = df.select(column_name).distinct().rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "    # Check if all distinct values are in the set {0, 1}\n",
    "    is_binary = set(distinct_values).issubset({0, 1})\n",
    "\n",
    "    assert is_binary, (\n",
    "        f\"Column '{column_name}' contains non-binary values: {set(distinct_values)}\"\n",
    "    )\n",
    "    print(f\"Column '{column_name}' is binary (0 or 1).\")\n",
    "\n",
    "\n",
    "def validate_double_column(df, column_name):\n",
    "    \"\"\"\n",
    "    Validates that the specified column in the DataFrame is of type double.\n",
    "\n",
    "    Parameters:\n",
    "    - df: The PySpark DataFrame to check.\n",
    "    - column_name: The name of the column to validate.\n",
    "\n",
    "    Uses:\n",
    "    - AssertionError if the column is not of type double.\n",
    "    \"\"\"\n",
    "    # Get the data type of the column\n",
    "    column_data_type = df.schema[column_name].dataType\n",
    "\n",
    "    # Check if the data type is DoubleType\n",
    "    is_double = isinstance(column_data_type, DoubleType)\n",
    "\n",
    "    assert is_double, (\n",
    "        f\"Column '{column_name}' is not of type double. Found type: {column_data_type}\"\n",
    "    )\n",
    "    print(f\"Column '{column_name}' is of type double.\")\n",
    "\n",
    "def validate_non_negative_values(df):\n",
    "    \"\"\"\n",
    "    Validates that all columns in the given PySpark DataFrame contain non-negative values (>= 0).\n",
    "\n",
    "    Parameters:\n",
    "    - df: The PySpark DataFrame to check.\n",
    "\n",
    "    Uses:\n",
    "    - AssertionError if any column contains negative values.\n",
    "    \"\"\"\n",
    "    from pyspark.sql.functions import col, min\n",
    "\n",
    "    negative_values = df.agg(*[\n",
    "        min(col(c)).alias(c) for c in df.columns\n",
    "    ]).collect()[0].asDict()\n",
    "\n",
    "    negative_columns = {col: negative_values[col] for col in df.columns if negative_values[col] < 0}\n",
    "\n",
    "    assert not negative_columns, (\n",
    "        f\"Negative values found in the following columns: {negative_columns}\"\n",
    "    )\n",
    "    print(\"All columns contain non-negative values!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e343cea-7ab6-4fd2-9ccb-93091e357047",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Define expected schema for our DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9ef59c6-d013-49cc-9ef4-0af3b6db4234",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, DoubleType, LongType, IntegerType\n",
    "\n",
    "# Define the complete expected schema\n",
    "expected_schema = StructType([\n",
    "    StructField(\"Diabetes_binary\", IntegerType(), True),\n",
    "    StructField(\"HighBP\", IntegerType(), True),\n",
    "    StructField(\"HighChol\", DoubleType(), True),\n",
    "    StructField(\"CholCheck\", DoubleType(), True),\n",
    "    StructField(\"BMI\", IntegerType(), True),\n",
    "    StructField(\"Smoker\", IntegerType(), True),\n",
    "    StructField(\"Stroke\", IntegerType(), True),\n",
    "    StructField(\"HeartDiseaseorAttack\", IntegerType(), True),\n",
    "    StructField(\"PhysActivity\", DoubleType(), True),\n",
    "    StructField(\"Fruits\", DoubleType(), True),\n",
    "    StructField(\"Veggies\", DoubleType(), True),\n",
    "    StructField(\"HvyAlcoholConsump\", DoubleType(), True),\n",
    "    StructField(\"AnyHealthcare\", DoubleType(), True),\n",
    "    StructField(\"NoDocbcCost\", DoubleType(), True),\n",
    "    StructField(\"GenHlth\", DoubleType(), True),\n",
    "    StructField(\"MentHlth\", DoubleType(), True),\n",
    "    StructField(\"PhysHlth\", DoubleType(), True),\n",
    "    StructField(\"DiffWalk\", DoubleType(), True),\n",
    "    StructField(\"Sex\", DoubleType(), True),\n",
    "    StructField(\"Age\", DoubleType(), True),\n",
    "    StructField(\"Education\", DoubleType(), True),\n",
    "    StructField(\"Income\", DoubleType(), True),\n",
    "    StructField(\"id\", LongType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e701be6a-33cf-4491-b56e-ca65341346d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's now run our validation functions and debug any errors that arise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33012659-1e9f-4ede-a6bd-8c8eab254da6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# run validation tests\n",
    "validate_schema(df, expected_schema)\n",
    "validate_no_missing_values(df)\n",
    "validate_binary_column(df, \"HeartDiseaseorAttack\")\n",
    "validate_double_column(df, \"Age\")\n",
    "validate_non_negative_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1657e5b2-4caf-4d20-80a3-6b8745d4a5ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Oh no! We seem to have an AssertionError indicating there's been some faulty entry. It looks like there is a record within the HeartDiseaseorAttack feature that has a value of -1. After talking to the data team, it turns out there was some faulty logic (a typo if you can believe it) that converted this to -1 from 1. Let's clean this up and continue our validations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "277e7f53-d3f7-4e52-b677-a2b8321a0a83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "# convert values in HeartDiseaseorAttack that are -1 to 1\n",
    "df = df.withColumn(\"HeartDiseaseorAttack\", when(df.HeartDiseaseorAttack == -1, 1).otherwise(df.HeartDiseaseorAttack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3aa97ddc-e8e2-477a-b6f0-01ccb15d022b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "validate_binary_column(df, \"HeartDiseaseorAttack\")\n",
    "validate_double_column(df, \"Age\")\n",
    "validate_non_negative_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f47948c-9524-4633-8279-a9b879816926",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data Transformations\n",
    "\n",
    "Transformation testing involved validating and verifying the operations applied to raw data to prepare it for use in a machine learning pipeline. These transformations include cleaning, scaling, encoding, and feature extraction, which are critical for ensuring that the data fed into the model aligns with the intended assumptions. Here we will consider performing a normalization test on the `Age` feature and validating that the transformation has been applied correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2df0fb0-d2fa-46c1-b8ed-7acd73a359db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Define Helper Functions\n",
    "\n",
    "These helper functions ensure proper normalization of a DataFrame column and validate the process. \n",
    "\n",
    "- `normalize_column` creates a normalized version of a specified column by subtracting its mean and dividing by its standard deviation, appending the result as a new column in the DataFrame.\n",
    "- `test_column_normalized` verifies the correctness of the normalization by checking if the resulting columnâ€™s mean is approximately 0 and its standard deviation is approximately 1, within a small tolerance, to confirm accurate scaling for downstream analysis or modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd7e5f0f-a358-4453-a5ec-bd78b5a90c5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This function will normalize the dataframe's column\n",
    "def normalize_column(df, column):\n",
    "    if column not in df.columns:\n",
    "        raise AssertionError(f\"Column '{column}' does not exist in the DataFrame.\")\n",
    "    \n",
    "    # Simulate a normalized column for demonstration\n",
    "    df[f'{column}_normalized'] = (df[column] - df[column].mean()) / df[column].std()\n",
    "    return df\n",
    "\n",
    "# Test function to check normalization\n",
    "def test_column_normalized(df, column):\n",
    "    if column not in df.columns:\n",
    "        raise AssertionError(f\"Column '{column}' does not exist in the DataFrame.\")\n",
    "    \n",
    "    mean = np.mean(df[column])\n",
    "    std = np.std(df[column])\n",
    "    \n",
    "    # Allowing a small tolerance for floating-point arithmetic\n",
    "    tolerance = 1e-4\n",
    "    assert abs(mean) < tolerance, f\"Mean of column '{column}' is not approximately 0. It is {mean}.\"\n",
    "    assert abs(std - 1) < tolerance, f\"Standard deviation of column '{column}' is not approximately 1. It is {std}.\"\n",
    "    print(f\"Column '{column}' is properly normalized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "076adc5d-effd-4f44-91cd-fd258cce0127",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Normalization Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a2f3a7f-2469-4d04-a28c-bf334e367ec0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format('delta').table('diabetes').toPandas()\n",
    "df = normalize_column(df, 'Age')\n",
    "test_column_normalized(df, 'Age_normalized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "041c8fde-351d-460b-8926-dfee84b594d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Model Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1a38cc7-a8e3-414c-90c1-04cc1b0a5489",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Copy and paste the url for the model serving endpoint. Locate your endpoint under **Serving** and click on it. Then copy the **URL**. Paste it in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a108c801-693e-40ee-a08d-798fcf37402d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Retrieve the API URL and token using dbutils\n",
    "API_URL = f\"https://{spark.conf.get('spark.databricks.workspaceUrl')}/serving-endpoints/M02-endpoint_{DA.schema_name}/invocations\"\n",
    "TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().getOrElse(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29570e17-d9e5-46d5-a70c-d440afef469a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Define Helper Functions\n",
    "\n",
    "The function, `test_model_endpoint_status`, checks whether a model serving endpoint is operational by sending a test dataset as a request and verifying that it returns a 200 status code. It prepares the input dataset in the expected JSON format, sends it to the endpoint using a POST request with appropriate headers, and evaluates the response. If the status code is 200, it confirms the endpoint is functioning correctly; otherwise, it logs the error or response details. This function ensures the endpoint is ready to handle requests for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b68e0bf3-a77d-40fa-bc3f-d70b314ccf4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "def test_model_endpoint_status(dataset, url):\n",
    "    \"\"\"\n",
    "    Test if the model serving endpoint returns a 200 status code.\n",
    "    \n",
    "    Args:\n",
    "        dataset (pd.DataFrame): Input dataset to send to the model endpoint.\n",
    "        url (string): The URL of the model serving endpoint.\n",
    "    \n",
    "    Returns:\n",
    "        None. Prints the result of the test.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Make a request to the model endpoint using the score_model function\n",
    "        headers = {'Authorization': f'Bearer {TOKEN}', 'Content-Type': 'application/json'}\n",
    "        \n",
    "        # Prepare the data in the expected format\n",
    "        ds_dict = {'dataframe_split': dataset.to_dict(orient='split')}\n",
    "        data_json = json.dumps(ds_dict, allow_nan=True)\n",
    "        \n",
    "        # Send the request\n",
    "        response = requests.request(method='POST', headers=headers, url=url, data=data_json)\n",
    "        \n",
    "        # Check the status code\n",
    "        if response.status_code == 200:\n",
    "            print(\"Test passed: Endpoint returned status code 200.\")\n",
    "        else:\n",
    "            print(f\"Test failed: Endpoint returned status code {response.status_code}. Response: {response.text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Test failed with error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4678061-4652-4264-9d9d-aa83617f4b5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ds_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44851c80-5540-4f10-a858-236108d6376c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Test Endpoint Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a89b1cb-8475-4eec-9e2c-4f554a6dd65a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#grab the first row of the pandas dataframe X_test\n",
    "X_test.iloc[[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a4dae69-fdaf-4a02-976e-1a17a30eb34d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Note that the following code might not run quickly since we set up our endpoint to scale to zero. If we run it again we will see much small latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bf7b7bb-6f03-444e-b602-a5bf9bcb4320",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Call the test function in your Databricks notebook\n",
    "test_model_endpoint_status(X_test.iloc[[0]], url = API_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "947f5856-23f4-4f9b-abb7-54012366d825",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Modeling Functions\n",
    "\n",
    "Model testing involves training, prediction, and evaluation of ML models as a part of the ML pipeline. Unit tests and integration tests are foundational components and should be considered separately. Here we will consider inference as an example to determine if the F1-score and accuracy are what we expect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52b1439e-6036-4766-b962-7fbaf6f6d085",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Define Helper Functions\n",
    "\n",
    "The following function, `test_model_performance`, evaluates a logged MLflow modelâ€™s performance on a test dataset by calculating its F1-score and accuracy. It loads the model using its URI, generates predictions on the test features, and compares the calculated metrics against specified thresholds. If the F1-score or accuracy falls below the thresholds, the function raises an assertion error; otherwise, it confirms the model meets the performance criteria and prints the metrics. This ensures the modelâ€™s predictions align with expected performance levels before deployment or further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25e22443-236a-4a5e-9a4d-3e95c7440131",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "def test_model_performance(model_uri, X_test, y_test, f1_threshold=0.7, accuracy_threshold=0.8):\n",
    "    \"\"\"\n",
    "    Test function to evaluate a logged MLflow model on a test dataset.\n",
    "    \n",
    "    Args:\n",
    "        model_uri (str): URI of the logged MLflow model.\n",
    "        X_test (pd.DataFrame): Test features.\n",
    "        y_test (pd.Series): True labels for the test set.\n",
    "        f1_threshold (float): Minimum acceptable F1-score.\n",
    "        accuracy_threshold (float): Minimum acceptable accuracy score.\n",
    "    \n",
    "    Raises:\n",
    "        AssertionError: If model performance metrics do not meet expected thresholds.\n",
    "    \"\"\"\n",
    "    # Step 1: Load the model from MLflow\n",
    "    model = mlflow.pyfunc.load_model(model_uri)\n",
    "    \n",
    "    # Step 2: Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Step 3: Calculate evaluation metrics\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Step 4: Assert performance thresholds\n",
    "    assert f1 >= f1_threshold, f\"F1-score {f1:.4f} is below the threshold of {f1_threshold:.2f}.\"\n",
    "    assert accuracy >= accuracy_threshold, f\"Accuracy {accuracy:.4f} is below the threshold of {accuracy_threshold:.2f}.\"\n",
    "\n",
    "    # Step 5: Print metrics and success message\n",
    "    print(f\"Model performance passed all thresholds.\")\n",
    "    print(f\"F1-score: {f1:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4be158d-a241-4267-ba32-299dae0651b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Testing Expected F1-Score and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67c4d635-2dac-42bd-9efd-ba566eea1bfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example usage of the test function\n",
    "try:\n",
    "    test_model_performance(\n",
    "        model_uri=model_uri,\n",
    "        X_test=X_test,\n",
    "        y_test=y_test,\n",
    "        f1_threshold=0.7,  # Custom threshold for F1-score\n",
    "        accuracy_threshold=0.7  # Custom threshold for accuracy\n",
    "    )\n",
    "except AssertionError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a41277d8-0f1c-4444-94ff-f40d751280b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Testing Frameworks\n",
    "\n",
    "Unit tests are essential in the ML development process. They verify that individual components of your code. For example, it's common practice to check that functions or methods function as intended by data scientists and machine learning practitioners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3c3d897-1bbc-4daa-b587-2472daf68c95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Unittest\n",
    "\n",
    "unittest involves testing individual components of an ML pipeline to ensure correctness and reliability. Since machine learning pipelines consist of multiple stagesâ€”data preprocessing, feature engineering, model training, evaluation, and inferenceâ€”unit testing helps validate the behavior of each component in isolation. Here we will consider unit tests for schema validation and checking missing values. \n",
    "\n",
    "**Why use unittest?**\n",
    "\n",
    "Using unittest is better than writing individual functions for testing because it provides a structured, standardized, and scalable framework for managing and executing tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79234933-9375-45a5-bce3-184c154a6118",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Validating Schema and Missing and Non-negative Values\n",
    "\n",
    "Here we will return back to our first example and use unittest for data validation. Here, we will validate the schema, that no missing values are present, and non-negative values are not present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "841e6397-d8d8-44a9-8a0e-3113ea4fafe4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, IntegerType, LongType\n",
    "from pyspark.sql.functions import col, sum, min\n",
    "\n",
    "\n",
    "class TestDataValidation(unittest.TestCase):\n",
    "    \"\"\"\n",
    "    Unit tests for schema validation, missing values, and non-negative values in PySpark DataFrames.\n",
    "    \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        \"\"\"\n",
    "        Set up shared resources for the tests.\n",
    "        \"\"\"\n",
    "        # Load the test DataFrame (assume a table named 'diabetes' is present)\n",
    "        cls.df = spark.read.format(\"delta\").table(\"diabetes\").select(\n",
    "            'id', 'Diabetes_binary', 'HighBP', 'BMI', 'Smoker', 'Stroke', \n",
    "            'HeartDiseaseorAttack', 'Age'\n",
    "        )\n",
    "\n",
    "    def test_validate_schema(self):\n",
    "        \"\"\"\n",
    "        Test if the DataFrame schema matches the expected schema.\n",
    "        \"\"\"\n",
    "        expected_schema = StructType([\n",
    "            StructField(\"id\", LongType(), True),\n",
    "            StructField(\"Diabetes_binary\", IntegerType(), True),\n",
    "            StructField(\"HighBP\", IntegerType(), True),\n",
    "            StructField(\"BMI\", IntegerType(), True),\n",
    "            StructField(\"Smoker\", IntegerType(), True),\n",
    "            StructField(\"Stroke\", IntegerType(), True),\n",
    "            StructField(\"HeartDiseaseorAttack\", IntegerType(), True),\n",
    "            StructField(\"Age\", DoubleType(), True),\n",
    "        ])\n",
    "        actual_schema = self.df.schema\n",
    "        self.assertEqual(\n",
    "            actual_schema, expected_schema,\n",
    "            f\"Schema validation failed.\\nExpected: {expected_schema}\\nActual: {actual_schema}\"\n",
    "        )\n",
    "\n",
    "    def test_validate_no_missing_values(self):\n",
    "        \"\"\"\n",
    "        Test that there are no missing (null) values in the DataFrame.\n",
    "        \"\"\"\n",
    "        missing_values = self.df.agg(*[\n",
    "            sum(col(c).isNull().cast(\"int\")).alias(c) for c in self.df.columns\n",
    "        ]).collect()[0].asDict()\n",
    "\n",
    "        missing_columns = {col: missing_values[col] for col in self.df.columns if missing_values[col] > 0}\n",
    "        self.assertFalse(\n",
    "            missing_columns,\n",
    "            f\"Missing values found in the following columns: {missing_columns}\"\n",
    "        )\n",
    "\n",
    "    def test_validate_non_negative_values(self):\n",
    "        \"\"\"\n",
    "        Test that all columns in the DataFrame contain non-negative values (>= 0).\n",
    "        \"\"\"\n",
    "        negative_values = self.df.agg(*[\n",
    "            min(col(c)).alias(c) for c in self.df.columns\n",
    "        ]).collect()[0].asDict()\n",
    "\n",
    "        negative_columns = {col: negative_values[col] for col in self.df.columns if negative_values[col] < 0}\n",
    "        self.assertFalse(\n",
    "            negative_columns,\n",
    "            f\"Negative values found in the following columns: {negative_columns}\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Run the tests\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestDataValidation)\n",
    "unittest.TextTestRunner().run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6f5341e-2551-490b-912d-b024c69d8390",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Notice that since we used our original DataFrame `df` that we are receiving the error about the negative value as intended!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "780706ba-d33f-46f8-879c-e042a61ec3d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## (Optional Read) pytest\n",
    "\n",
    "Another testing framework that is popular for Python users is called pytest. pytest can be fully integrated into Databricks. You can read the documentation on implementing it within Databricks [here](https://docs.databricks.com/en/dev-tools/vscode-ext/pytest.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efdefa0f-7f7a-4b80-b512-28d842129da1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Conclusion\n",
    "In this demonstration, we looked at common testing strategies. We utilized MLflow and Unity Catalog for model training, Packaging, and registration. We also utilized Mosaic AI Model serving to showcase how to test for expected evaluation metrics and integrated endpoints. Finally, we looked at how unittest can be used in place of individual Python functions for testing machine learning pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d200b5cd-faaa-4a21-9566-82356c8146c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2026 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2.1 Demo - Common Testing Strategies",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
