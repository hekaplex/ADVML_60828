{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90ce6e85-8009-4ffc-8ddc-ccd94460dcbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ffc00f4-b72d-4852-b3d7-92466348726d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Workflow Notebook - Normalization Validation\n",
    "\n",
    "1. **Purpose of the Notebook**:\n",
    "   - In this notebook, called **Features Validation**, we will validate the feature table created in the previous notebook.\n",
    "\n",
    "2. **Validation Process**:\n",
    "   - The feature table is read from the **Feature Store**.\n",
    "   - The focus is on testing whether **normalization** has been correctly applied to the **normalized column** (e.g., the Age column).\n",
    "\n",
    "3. **Expected Outcome**:\n",
    "   - If normalization has occurred properly, you will receive a confirmation message indicating that the column has been correctly normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd6ca976-8075-468c-beeb-97d22d1ff577",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog = dbutils.widgets.get(<FILL_IN>)\n",
    "schema = dbutils.widgets.get(<FILL_IN>)\n",
    "normalized_column = dbutils.widgets.get(<FILL_IN>)\n",
    "silver_table_name = dbutils.widgets.get(<FILL_IN>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78502389-5b96-477a-bab3-df3e8847e515",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "catalog = dbutils.widgets.get('catalog')\n",
    "schema = dbutils.widgets.get('schema')\n",
    "normalized_column = dbutils.widgets.get('normalized_column')\n",
    "silver_table_name = dbutils.widgets.get('silver_table_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90d95b09-bd2b-41ed-9451-1da50f42036d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "\n",
    "# Instantiate the FeatureEngineeringClient\n",
    "fe = FeatureEngineeringClient()\n",
    "\n",
    "spark.sql(f\"USE {catalog}.{schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a491222e-0284-4534-9e37-90795cbbf188",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Test function to check normalization\n",
    "def test_column_normalized(df, column):\n",
    "    if column not in df.columns:\n",
    "        raise <FILL_IN>(f\"Column '{column}' does not exist in the DataFrame.\")\n",
    "    \n",
    "    mean = <FILL_IN>\n",
    "    std = <FILL_IN>\n",
    "    \n",
    "    # Allowing a small tolerance for floating-point arithmetic\n",
    "    tolerance = 1e-4\n",
    "    <FILL_IN> abs(mean) < tolerance, f\"Mean of column '{column}' is not approximately 0. It is {mean}.\"\n",
    "    <FILL_IN> abs(std - 1) < tolerance, f\"Standard deviation of column '{column}' is not approximately 1. It is {std}.\"\n",
    "    print(f\"Column '{column}' is properly normalized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1ca3839-833e-4e7e-855b-2b692346bfb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "import numpy as np\n",
    "\n",
    "# Test function to check normalization\n",
    "def test_column_normalized(df, column):\n",
    "    if column not in df.columns:\n",
    "        raise AssertionError(f\"Column '{column}' does not exist in the DataFrame.\")\n",
    "    \n",
    "    mean = np.mean(df[column])\n",
    "    std = np.std(df[column])\n",
    "    \n",
    "    # Allowing a small tolerance for floating-point arithmetic\n",
    "    tolerance = 1e-4\n",
    "    assert abs(mean) < tolerance, f\"Mean of column '{column}' is not approximately 0. It is {mean}.\"\n",
    "    assert abs(std - 1) < tolerance, f\"Standard deviation of column '{column}' is not approximately 1. It is {std}.\"\n",
    "    print(f\"Column '{column}' is properly normalized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c8b873e-33d5-4d3e-a5be-2385c2b57c2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# read table from feature store\n",
    "df2 = <FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68a65753-e34e-419e-9c7b-41b3b764e791",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "# read table from feature store\n",
    "df2 = fe.read_table(name=f'{silver_table_name}_features').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f2cad6a5-83f6-4262-8471-6564da806acf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_column_normalized(<FILL_IN>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dbc6dd27-d062-43c8-8cc2-64856cfa31fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "\n",
    "test_column_normalized(df2, f'{normalized_column}_normalized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c36415f-6c49-4f39-9444-9b81acf21b2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2026 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "03 - Normalization Validation",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
