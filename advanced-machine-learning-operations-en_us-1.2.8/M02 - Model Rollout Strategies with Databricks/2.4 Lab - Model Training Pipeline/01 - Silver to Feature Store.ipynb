{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7cf77d4-848c-41a2-bb4d-2f53d011fd16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7746b576-1d14-4479-a8d1-c986917cf67f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Workflow Notebook - Silver to Feature Store\n",
    "\n",
    "1. **Widgets at the Top**:\n",
    "   - In this notebook, you will find several parameterized widgets:\n",
    "     - **catalog**\n",
    "     - **column**\n",
    "     - **primary_key**\n",
    "     - **schema**\n",
    "     - **silver_table_name**\n",
    "     - **target_column**\n",
    "\n",
    "2. **Purpose of Parameterization**:\n",
    "   - These widgets allow you to configure parameters dynamically when setting up workflows.\n",
    "   - Instead of modifying hard-coded values in the notebook, you can edit the parameters directly in the Databricks Workflows UI.\n",
    "\n",
    "3. **Notebook Functionality**:\n",
    "   - This notebook focuses on **feature engineering**.\n",
    "   - Specifically, it normalizes the **Age** column and generates a feature table.\n",
    "   - The resulting feature table is stored in the **Feature Store** for use in downstream tasks like model training or evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c093750c-435b-4469-a832-0f770bc6d890",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Read in silver-layer data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ae75a01-aeb9-4300-90e9-6555997d6b2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog = dbutils.widgets.get(<FILL_IN>)\n",
    "schema = dbutils.widgets.get(<FILL_IN>)\n",
    "spark.sql(f\"USE {catalog}.{schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bac983a5-8a3e-4560-80e8-847591b14305",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "catalog = dbutils.widgets.get(\"catalog\")\n",
    "schema = dbutils.widgets.get(\"schema\")\n",
    "spark.sql(f\"USE {catalog}.{schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1abd9945-2c37-48ff-8cf8-3b3d7db428a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "silver_table_name = dbutils.widgets.get(<FILL_IN>)\n",
    "df = spark.read.format('delta').table(<FILL_IN>).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39020e33-2f31-43ce-9d8d-f7cef0b4015d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "silver_table_name = dbutils.widgets.get(\"silver_table_name\")\n",
    "df = spark.read.format('delta').table(silver_table_name).select('id', 'Diabetes_binary', 'HighBP', 'BMI', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', 'Age'). toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e88aaa56-22a5-49ab-9f9b-5c1d6e4a3be1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Perform feature engineering - normalize your column of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a66d93b-5a46-4b34-a55f-f82edb140cf0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "\n",
    "## Instantiate the FeatureEngineeringClient\n",
    "fe = FeatureEngineeringClient()\n",
    "\n",
    "## Normalize the Age column and store it as Age_normalized\n",
    "\n",
    "column = dbutils.widgets.get(<FILL_IN>)\n",
    "target_column = dbutils.widgets.get(<FILL_IN>)\n",
    "\n",
    "df[f'{column}_normalized'] = <FILL_IN>\n",
    "\n",
    "\n",
    "df = df.drop(target_column, axis=1)\n",
    "df = df.drop(column, axis=1)\n",
    "normalized_df = spark.createDataFrame(df)\n",
    "\n",
    "primary_key = dbutils.widgets.get(<FILL_IN>)\n",
    "\n",
    "## Set the feature table name for storage in UC\n",
    "feature_table_name = f'{<FILL_IN>}.{<FILL_IN>}.{<FILL_IN>}_features'\n",
    "\n",
    "## print(f\"The name of the feature table: {feature_table_name}\\n\\n\")\n",
    "\n",
    "spark.sql(f'drop table if exists {feature_table_name}')\n",
    "\n",
    "## Create the feature table\n",
    "fe.create_table(\n",
    "    <FILL_IN>\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc9ba31d-bb78-4fc5-bc52-11fb03dc6be4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "\n",
    "## Instantiate the FeatureEngineeringClient\n",
    "fe = FeatureEngineeringClient()\n",
    "\n",
    "## Normalize the Age column and store it as Age_normalized\n",
    "\n",
    "column = dbutils.widgets.get(\"column\")\n",
    "target_column = dbutils.widgets.get(\"target_column\")\n",
    "\n",
    "df[f'{column}_normalized'] = (df[column] - df[column].mean()) / df[column].std()\n",
    "\n",
    "\n",
    "df = df.drop(target_column, axis=1)\n",
    "df = df.drop(column, axis=1)\n",
    "normalized_df = spark.createDataFrame(df)\n",
    "\n",
    "primary_key = dbutils.widgets.get(\"primary_key\")\n",
    "\n",
    "## Set the feature table name for storage in UC\n",
    "feature_table_name = f'{catalog}.{schema}.{silver_table_name}_features'\n",
    "\n",
    "## print(f\"The name of the feature table: {feature_table_name}\\n\\n\")\n",
    "\n",
    "spark.sql(f'drop table if exists {feature_table_name}')\n",
    "\n",
    "## Create the feature table\n",
    "fe.create_table(\n",
    "    name = feature_table_name,\n",
    "    primary_keys = primary_key,\n",
    "    df = normalized_df, \n",
    "    description=\"{schema} quality features\", \n",
    "    tags = {\"source\": \"silver\", \"format\": \"delta\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d64f502-5a82-438b-9890-a976894d2a8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2026 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "01 - Silver to Feature Store",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
