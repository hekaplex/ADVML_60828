{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3167eef-6f6a-46d4-9a66-b49a2f8f2234",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "beb960fc-e45c-4272-aef1-c6f1e23e0ed7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Workflow Notebook - Features Validation\n",
    "\n",
    "1. **Purpose of the Notebook**:\n",
    "   - In this notebook, called **Features Validation**, we will validate the feature table created in the previous notebook.\n",
    "\n",
    "2. **Validation Process**:\n",
    "   - The feature table is read from the **Feature Store**.\n",
    "   - The focus is on testing whether **normalization** has been correctly applied to the **normalized column** (e.g., the Age column).\n",
    "\n",
    "3. **Expected Outcome**:\n",
    "   - If normalization has occurred properly, you will receive a confirmation message indicating that the column has been correctly normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03eb3783-e2b0-4261-b623-936614a020b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog = dbutils.widgets.get('catalog')\n",
    "schema = dbutils.widgets.get('schema')\n",
    "normalized_column = dbutils.widgets.get('normalized_column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "442d9d02-dc0b-4bea-bfe6-5a761b812426",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "\n",
    "# Instantiate the FeatureEngineeringClient\n",
    "fe = FeatureEngineeringClient()\n",
    "\n",
    "spark.sql(f\"USE {catalog}.{schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "090d23da-18a9-4fa4-8ec6-d15b87bfe59e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Test function to check normalization\n",
    "def test_column_normalized(df, column):\n",
    "    if column not in df.columns:\n",
    "        raise AssertionError(f\"Column '{column}' does not exist in the DataFrame.\")\n",
    "    \n",
    "    mean = np.mean(df[column])\n",
    "    std = np.std(df[column])\n",
    "    \n",
    "    # Allowing a small tolerance for floating-point arithmetic\n",
    "    tolerance = 1e-4\n",
    "    assert abs(mean) < tolerance, f\"Mean of column '{column}' is not approximately 0. It is {mean}.\"\n",
    "    assert abs(std - 1) < tolerance, f\"Standard deviation of column '{column}' is not approximately 1. It is {std}.\"\n",
    "    print(f\"Column '{column}' is properly normalized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05b2a021-3317-4877-afb5-58ce59be8fe3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# read table from feature store\n",
    "df2 = fe.read_table(name=f'diabetes_features').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b5998d3-476b-4e19-93e9-e96d15b6f6f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_column_normalized(df2, f'{normalized_column}_normalized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1fd31d51-4f30-47a0-ac32-475196efa39e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2026 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02 Features Validation",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
