{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68e3ae85-495b-44ff-b806-1b1d807c1506",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b90d969-3541-47b5-8e72-42a588c329f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Workflow Notebook - Train Model on Validated Features\n",
    "\n",
    "1. **Purpose of the Notebook**:\n",
    "   - In this third notebook, called **Train Model on Features**, we will train a machine learning model using the **validated features** from the previous notebook.\n",
    "\n",
    "2. **Process**:\n",
    "   - The validated feature table is read and used as input for model training.\n",
    "   - The resulting model is stored in **Unity Catalog** for centralized management and accessibility.\n",
    "\n",
    "3. **Next Steps**:\n",
    "   - After training, the next logical step is to **validate the model** by evaluating its performance using metrics such as accuracy, precision, recall, or F1-score, ensuring its readiness for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be4ebf01-286d-4824-b44b-8e0ed01faaf6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog = dbutils.widgets.get('catalog')\n",
    "schema = dbutils.widgets.get('schema')\n",
    "primary_key = dbutils.widgets.get('primary_key')\n",
    "target_column = dbutils.widgets.get('target_column')\n",
    "username = dbutils.widgets.get('username')\n",
    "silver_table_name = dbutils.widgets.get('silver_table_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dfd396cb-71fc-4ac4-b30b-fcd0207e9d9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"USE {catalog}.{schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e3c3d49-8164-4131-ae3b-e6e735a810a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "df = spark.read.format('delta').table(f'{silver_table_name}_features')\n",
    "\n",
    "# Read in the original dataset as well and join with df\n",
    "original_df = spark.read.format('delta').table(f'{silver_table_name}').select(primary_key, target_column)\n",
    "df = df.join(original_df, on=primary_key)\n",
    "\n",
    "training_df = df.toPandas()\n",
    "\n",
    "X = training_df.drop([primary_key, target_column], axis=1)\n",
    "y = training_df[target_column]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# set the path for mlflow experiment\n",
    "mlflow.set_experiment(f\"/Users/{username}/{schema}_model\")\n",
    "\n",
    "with mlflow.start_run(run_name = 'mlflow-run') as run:  \n",
    "    # Initialize the Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "    # Enable automatic logging of input samples, metrics, parameters, and models\n",
    "    mlflow.sklearn.autolog(\n",
    "        log_input_examples = True,\n",
    "        silent = True\n",
    "    )\n",
    "        \n",
    "    mlflow.sklearn.log_model(\n",
    "        rf_classifier,\n",
    "        artifact_path = \"model-artifacts\", \n",
    "        input_example=X_train[:3],\n",
    "        signature=infer_signature(X_train, y_train)\n",
    "    )\n",
    "\n",
    "    model_uri = f\"runs:/{run.info.run_id}/model-artifacts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "135cc442-4cbb-4ba0-9850-584e2a481f8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Register the model in the model registry\n",
    "registered_model = mlflow.register_model(model_uri=model_uri, name=f\"{catalog}.{schema}.workflows_classifier_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6b3fc52-e0cc-4da0-95f8-a4b945fce0ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2026 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03  Train Model on Validated Features",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
