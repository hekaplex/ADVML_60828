{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "932e7b20-ce01-4863-9227-8d015d3f665d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b165629-6729-4b01-a814-38f25eab9866",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Lab - Monitoring Drift with Lakehouse Monitoring\n",
    "\n",
    "In this lab, you will investigate how to monitor drift. You will work through a series of practical exercises to simulate prediction drift, set up monitoring for inference tables, and analyze drift metrics. The lab also includes hands-on tasks to explore visual dashboards, extract and modify SQL code, and create custom alerts. Additionally, you will learn to inspect lineage, enabling you to trace the flow of data and associated dashboards and queries.\n",
    "\n",
    "\n",
    "**Learning Objectives**\n",
    "By the end of this lab, you will have completed the following:\n",
    "- Initiate Lakehouse Monitoring programmatically\n",
    "- Inspect automatically generated Dashboard\n",
    "- Create a new widget in the monitoring dashboard\n",
    "- Inspect Profile and Drift Metrics tables\n",
    "- Setup an Alert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab290a8c-603f-4164-a299-d2d8ef7417d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## REQUIRED - SELECT CLASSIC COMPUTE\n",
    "Before executing cells in this notebook, please select your classic compute cluster in the lab. Be aware that **Serverless** is enabled by default.\n",
    "Follow these steps to select the classic compute cluster:\n",
    "1. Navigate to the top-right of this notebook and click the drop-down menu to select your cluster. By default, the notebook will use **Serverless**.\n",
    "1. If your cluster is available, select it and continue to the next cell. If the cluster is not shown:\n",
    "   - In the drop-down, select **More**.\n",
    "   - In the **Attach to an existing compute resource** pop-up, select the first drop-down. You will see a unique cluster name in that drop-down. Please select that cluster.\n",
    "\n",
    "**NOTE:** If your cluster has terminated, you might need to restart it in order to select it. To do this:\n",
    "1. Right-click on **Compute** in the left navigation pane and select *Open in new tab*.\n",
    "1. Find the triangle icon to the right of your compute cluster name and click it.\n",
    "1. Wait a few minutes for the cluster to start.\n",
    "1. Once the cluster is running, complete the steps above to select your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "edb65a96-4d2c-420c-9da6-17a0f50ac2ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Requirements\n",
    "\n",
    "Please review the following requirements before starting the lesson:\n",
    "\n",
    "* To run this notebook, you need to use one of the following Databricks runtime(s): **17.3.x-cpu-ml-scala2.13**\n",
    "\n",
    "* To utilize the generated Dashboard, you will need a SQL Warehouse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7b70e6a-c39d-4586-81a3-b5590f4277e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Classroom Setup\n",
    "\n",
    "To get into the lesson, we first need to build some data assets and define some configuration variables required for this lab. When running the following cell, the output is hidden so our space isn't cluttered. To view the details of the output, you can hover over the next cell and click the eye icon. \n",
    "\n",
    "The cell after the setup, titled `View Setup Variables`, displays the various variables that were created. You can click the Catalog icon in the notebook space to the right to see that your catalog was created with no data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "301efbe2-7baa-41ca-bd86-b85761304ead",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../Includes/Classroom-Setup-3.Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a02b773d-a737-41f9-8225-20cc1ef9009d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Initiate Inference Monitoring\n",
    "\n",
    "Here you will use Python to initiate the monitoring of your inference table using Lakehouse Monitoring. This will generate two table: profile metrics and drift metrics. In addition, a Databricks Dashboard will also be generated. We will inspect all these assets later. \n",
    "\n",
    "Terminology: \n",
    "- Your **primary table** is your inference table you created by running the classroom setup. The name of this table is `model_logs`.\n",
    "- Your **baseline table** is your source of truth for your data. The name of this table is `baseline_features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7cf699a7-1fa5-4b86-bd81-a4543f729b67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.catalog import MonitorInferenceLog, MonitorInferenceLogProblemType, MonitorInfoStatus, MonitorRefreshInfoState, MonitorMetric\n",
    "w = WorkspaceClient()\n",
    "full_primary_table_name = <FILL_IN>\n",
    "full_baseline_table_name = <FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3b9c7c5-a6e5-4f56-b2bb-159c374e6116",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.catalog import MonitorInferenceLog, MonitorInferenceLogProblemType, MonitorInfoStatus, MonitorRefreshInfoState, MonitorMetric\n",
    "w = WorkspaceClient()\n",
    "full_primary_table_name = f'{DA.catalog_name}.{DA.schema_name}.model_logs'\n",
    "full_baseline_table_name = f\"{DA.catalog_name}.{DA.schema_name}.baseline_features\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7fe4b781-c07c-4b02-aabc-ca7bb98d5fcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "During the initial classroom setup, we registered our inference table with Unity Catalog that contained features, predictions, and labels for a classification problem. Next, we will set essential variables that will be used for enabling Lakehouse Monitoring and initiate monitoring. \n",
    "\n",
    "Configure the setup with the following conditions. \n",
    "1. Set the window size to **1 day**\n",
    "1. Store the generated notebook in a folder in your homeworkspace with the path `<username>/My_Monitored_Dashboards/Drift_Detection`\n",
    "1. Set the slicer to include `Ages` between 3 and 10 and `HvyAlcoholConsump` to be 1 (non-alcoholic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd93bb7a-2217-4675-a473-f48b3e3cf287",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## ML problem type, either \"classification\" or \"regression\"\n",
    "PROBLEM_TYPE = MonitorInferenceLogProblemType.<FILL_IN>\n",
    "\n",
    "## Window sizes to analyze data over\n",
    "GRANULARITIES = <FILL_IN>   \n",
    "\n",
    "## Directory to store generated dashboard\n",
    "ASSETS_DIR = f\"/Workspace/Users/{DA.username}/databricks_lakehouse_monitoring/{primary_table_name}\"\n",
    "\n",
    "## Optional parameters\n",
    "SLICING_EXPRS = <FILL_IN>   # Expressions to slice data with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aae8e140-57a5-47b6-a973-aadc9c415ff8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "\n",
    "## ML problem type, either \"classification\" or \"regression\"\n",
    "PROBLEM_TYPE = MonitorInferenceLogProblemType.PROBLEM_TYPE_CLASSIFICATION\n",
    "\n",
    "## Window sizes to analyze data over\n",
    "GRANULARITIES = [\"1 day\"]   \n",
    "\n",
    "## Directory to store generated dashboard\n",
    "ASSETS_DIR = f\"/Workspace/Users/{DA.username}/My_Monitored_Dashboards/Drift_Detection\"\n",
    "\n",
    "## Optional parameters\n",
    "SLICING_EXPRS = [\"Age < 10\", \"Age > 3\", \"HvyAlcoholConsump = 1\"]   # Expressions to slice data with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b334765c-7355-4d21-a1d5-68d5636c4a67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Run the initialization for Lakehouse Monitoring using the configuration above. Recall that for this dataset, we are interested in `Diabetes_binary` as our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a8077c9b-fc9a-4b82-9cbb-c804cc773709",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Creating monitor for model_logs\")\n",
    "try: \n",
    "  info = w.quality_monitors.create(\n",
    "    table_name=<FILL_IN>,\n",
    "    inference_log=MonitorInferenceLog(\n",
    "      timestamp_col='timestamp',\n",
    "      granularities=<FILL_IN>,\n",
    "      model_id_col='model_id',  ## Model version number \n",
    "      prediction_col=<FILL_IN>,  ## Ensure this column is of type DOUBLE\n",
    "      problem_type=<FILL_IN>,\n",
    "      label_col=<FILL_IN>  ## Ensure this column is of type DOUBLE\n",
    "    ),\n",
    "    baseline_table_name=<FILL_IN>,\n",
    "    slicing_exprs=<FILL_IN>,\n",
    "    output_schema_name=f\"{DA.catalog_name}.{DA.schema_name}\",\n",
    "    assets_dir=<FILL_IN>\n",
    "  )\n",
    "\n",
    "  import time\n",
    "\n",
    "  ## Wait for monitor to be created\n",
    "  while info.status ==  MonitorInfoStatus.MONITOR_STATUS_PENDING:\n",
    "    info = w.quality_monitors.get(table_name=<FILL_IN>)\n",
    "    time.sleep(10)\n",
    "\n",
    "  assert info.status == MonitorInfoStatus.MONITOR_STATUS_ACTIVE, \"Error creating monitor\"\n",
    "except Exception as e:\n",
    "  print(f\"Error creating monitor: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b7e926a-49f4-4420-8782-0ca23b4abaf9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "print(f\"Creating monitor for model_logs\")\n",
    "try: \n",
    "  info = w.quality_monitors.create(\n",
    "    table_name=full_primary_table_name,\n",
    "    inference_log=MonitorInferenceLog(\n",
    "      timestamp_col='timestamp',\n",
    "      granularities=GRANULARITIES,\n",
    "      model_id_col='model_id',  ## Model version number \n",
    "      prediction_col='Diabetes_binary',  ## Ensure this column is of type DOUBLE\n",
    "      problem_type=PROBLEM_TYPE,\n",
    "      label_col='labeled_data'  ## Ensure this column is of type DOUBLE\n",
    "    ),\n",
    "    baseline_table_name=full_baseline_table_name,\n",
    "    slicing_exprs=SLICING_EXPRS,\n",
    "    output_schema_name=f\"{DA.catalog_name}.{DA.schema_name}\",\n",
    "    assets_dir=ASSETS_DIR\n",
    "  )\n",
    "\n",
    "  import time\n",
    "\n",
    "  ## Wait for monitor to be created\n",
    "  while info.status ==  MonitorInfoStatus.MONITOR_STATUS_PENDING:\n",
    "    info = w.quality_monitors.get(table_name=full_primary_table_name)\n",
    "    time.sleep(10)\n",
    "\n",
    "  assert info.status == MonitorInfoStatus.MONITOR_STATUS_ACTIVE, \"Error creating monitor\"\n",
    "except Exception as e:\n",
    "  print(f\"Error creating monitor: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac635aa5-d2c8-4947-b5de-2cf4687ba9f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## A metric refresh will automatically be triggered on creation\n",
    "refreshes = w.quality_monitors.list_refreshes(table_name=<FILL_IN>).refreshes\n",
    "assert(len(refreshes) > 0)\n",
    "\n",
    "run_info = refreshes[0]\n",
    "while run_info.state in (MonitorRefreshInfoState.PENDING, MonitorRefreshInfoState.RUNNING):\n",
    "  run_info = w.quality_monitors.get_refresh(table_name=<FILL_IN>, refresh_id=run_info.refresh_id)\n",
    "  print(run_info)\n",
    "  time.sleep(30)\n",
    "\n",
    "assert run_info.state == MonitorRefreshInfoState.SUCCESS, \"Monitor refresh failed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9aaf0c6-d62f-48d4-9226-3ca175a14028",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "## A metric refresh will automatically be triggered on creation\n",
    "refreshes = w.quality_monitors.list_refreshes(table_name=full_primary_table_name).refreshes\n",
    "assert(len(refreshes) > 0)\n",
    "\n",
    "run_info = refreshes[0]\n",
    "while run_info.state in (MonitorRefreshInfoState.PENDING, MonitorRefreshInfoState.RUNNING):\n",
    "  run_info = w.quality_monitors.get_refresh(table_name=full_primary_table_name, refresh_id=run_info.refresh_id)\n",
    "  print(run_info)\n",
    "  time.sleep(30)\n",
    "\n",
    "assert run_info.state == MonitorRefreshInfoState.SUCCESS, \"Monitor refresh failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "524e4db8-035f-4306-97b5-48a80c27d086",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Locate the Monitoring Dashboard\n",
    "\n",
    "There are two methods for locating the monitoring Dashboard.\n",
    "\n",
    "1. Navigate to the underlying inference table `model_logs` and click on **Quality** and click on **View Dashboard**\n",
    "1. Navigate to the underlying inference table `model_logs` and click on **Lineage** and click on **Open in a dashboard** and find the dashboard you just created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ee25b91-3d3d-4a77-baed-bd34018aff3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Inspect Monitoring Dashboard\n",
    "\n",
    "1. After navigating to the canvas, scroll down until you see **Numerical Feature Drift**.\n",
    "1. Click on the kebab on the widget with title **# Features with Numerical Drift**.\n",
    "1. Click on **View Dataset**. This will take you to the generated **SQL code**. Modify it to not limit to the latest window by commenting out a single line.\n",
    "1. Copy and paste your answer in the next cell.\n",
    "\n",
    "**Do not run the SQL code** -  you will receive an error since you are working in a notebook. However, you can run the modified code in the Data tab of your dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ed82393-7be3-4134-bfeb-a0f38d4dfa0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Copy and paste the code you modified above. \n",
    "<FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e28e1d1f-7e69-48ce-a18b-25832d453e70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "\n",
    "WITH \n",
    "profile_metrics AS (\n",
    "  SELECT * FROM `dbacademy`.<`schema-name`>.`model_logs_profile_metrics`\n",
    "  WHERE window.start >= :`Time Window Start` AND window.end <= :`Time Window End` -- limit to the inspection time window range\n",
    "  AND isnull(slice_key) AND isnull(slice_value) -- default to \"No Slice\"\n",
    "  AND   `model_id`   = \"*\" -- default to all model ids\n",
    "),\n",
    "last_window_in_inspection_range AS (\n",
    "  SELECT window.start AS Window, granularity AS Granularity FROM profile_metrics\n",
    "  WHERE window.start IN (SELECT MAX(window.start) FROM profile_metrics) \n",
    "  ORDER BY Granularity LIMIT 1 -- order to ensure the `granularity` selected is stable\n",
    "),\n",
    "profile_metrics_inspected AS (\n",
    "  SELECT * FROM profile_metrics\n",
    "  WHERE Granularity = (SELECT Granularity FROM last_window_in_inspection_range)\n",
    ")\n",
    "SELECT\n",
    "  concat(window.start,\" - \", window.end) AS Window,\n",
    "  CONCAT('\"', ELEMENT_AT(frequent_items, 1).item, '\", ', CAST((ELEMENT_AT(frequent_items, 1).count / count) * 100 AS INT), \"%\") AS top_class,\n",
    "  granularity AS Granularity,\n",
    "    `model_id`   AS `Model Id`,\n",
    "  COALESCE(slice_key, \"No slice\") AS `Slice key`,\n",
    "  COALESCE(slice_value, \"No slice\") AS `Slice value`\n",
    "FROM profile_metrics_inspected\n",
    "WHERE\n",
    "  -- window.start IN (SELECT Window FROM last_window_in_inspection_range) -- limit to last window\n",
    "  log_type = \"INPUT\"\n",
    "  AND column_name = \"Diabetes_binary\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd6227f0-3cd3-40f5-9443-098623f9962a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> **⚠️ Note:**  \n",
    "> You may encounter a `CAST_INVALID_INPUT` error in the **Numerical Feature Quantile Drift** widget.  \n",
    "> This occurs because the auto-generated query attempts to cast the string `\"Baseline\"` to a `TIMESTAMP` type in the `Window` column.  \n",
    "> While this error does not affect other metrics or drift detection functionality, you can optionally resolve it using the steps below.\n",
    "\n",
    "**Steps to Diagnose and Fix the Error (Optional)**\n",
    "- **Step 1:**  \n",
    "  Navigate to the **Numerical Feature Quantile Drift** widget in the monitoring dashboard.  \n",
    "  If there's a rendering failure, you will see a `CAST_INVALID_INPUT` error message displayed within the widget.\n",
    "- **Step 2:**  \n",
    "  Click the **kebab menu (⋮)** in the top-right corner of the widget and select **View Dataset**.  \n",
    "  This opens the SQL query that powers the visual.\n",
    "- **Step 3:**  \n",
    "  In the dataset editor, scroll down and click **Diagnose error**.  \n",
    "  The Databricks Assistant will analyze the issue and provide a suggested fix.\n",
    "- **Step 4:**  \n",
    "  Click **Replace active cell content** to apply the Assistant’s suggested query.  \n",
    "  The corrected query will ensure the `Window` column in the baseline portion uses a proper timestamp type, typically by replacing `\"Baseline\"` with `CAST(NULL AS TIMESTAMP)`.\n",
    "- **Step 5:**  \n",
    "  Click **Run** to execute the updated query.\n",
    "- **Step 6:**  \n",
    "  Once the query runs successfully, the widget should render correctly, and the error message will disappear.\n",
    "This fix helps ensure type consistency in the `UNION` clause across datasets, resolving the rendering error in the visual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13542d86-0865-434d-a1ad-511580c9ebc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create a New Widget in the Canvas\n",
    "\n",
    "Next, create a new widget that provides a visual counter for the precision macro during the last window. \n",
    "\n",
    "Steps: \n",
    "1. Navigate to the canvas you just created. \n",
    "1. Copy or create a new visualization using the **Add a visualization** blue button at the bottom of the Canvas screen. \n",
    "1. Set the Dataset value to **performance_last_window**. \n",
    "1. Set the **Visualization** to **Counter**.\n",
    "1. Set the **Value** to **precision_macro**. \n",
    "1. Set the **Comparison** to **Window**.\n",
    "1. Give it a title **Precision Macro** as the **Title** and **In the last time window** for the **Description**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b24b6fc2-63b8-46ec-9209-fb6959c29c27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Inspect Profile and Drift Metrics \n",
    "\n",
    "Now we will turn our focus to inspecting the profile and drift metric tables that were created when we set up Lakehouse Monitoring. Let's read in both tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "667b425e-19d2-4f9f-a28d-cbfc10663059",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Display drift metrics table\n",
    "drift_table = f\"{DA.catalog_name}.{DA.schema_name}.<FILL_IN>\"\n",
    "drift_table_df = spark.sql(<FILL_IN>)\n",
    "display(drift_table_df.orderBy(F.rand()))\n",
    "\n",
    "## Display profile metrics table\n",
    "profile_table = f\"{DA.catalog_name}.{DA.schema_name}.<FILL_IN>\"\n",
    "profile_table_df = spark.sql(<FILL_IN>)\n",
    "display(drift_table_df.orderBy(F.rand()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da3d2fc4-73b3-47ae-bee3-651703489fb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "\n",
    "## Display drift metrics table\n",
    "drift_table = f\"{DA.catalog_name}.{DA.schema_name}.model_logs_drift_metrics\"\n",
    "drift_table_df = spark.sql(f\"SELECT * FROM {drift_table}\")\n",
    "display(drift_table_df.orderBy(F.rand()))\n",
    "\n",
    "## Display profile metrics table\n",
    "profile_table = f\"{DA.catalog_name}.{DA.schema_name}.model_logs_profile_metrics\"\n",
    "profile_table_df = spark.sql(f\"SELECT * FROM {profile_table}\")\n",
    "display(profile_table_df.orderBy(F.rand()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd424ae2-bc05-44a0-979f-a3f34b8874eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Use SQL to Analyze Profile Metrics Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "920841c5-2142-4250-8541-5cb7deb49521",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Next, display the profile metrics table where the baseline data was logged and the f1-score is not null and order by accuracy_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d5272ba-e468-4e90-878e-b529f7092804",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Display profile metrics table\n",
    "profile_table = f\"{DA.catalog_name}.{DA.schema_name}.model_logs_profile_metrics\"\n",
    "profile_table_df = spark.sql(f\"SELECT * FROM {profile_table} where f1_score is not null and log_type = 'BASELINE' order by accuracy_score\")\n",
    "display(profile_table_df.orderBy(F.rand()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d08a7954-8505-480f-9b58-6d3950b853bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Use SQL to inspect the drift metrics\n",
    "\n",
    "Use SQL to inspect drift metrics by finding all records where\n",
    "1. The drift type is baseline\n",
    "1. No slice key\n",
    "1. BMI data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9483ce7c-9af1-4127-9f33-c3815a97e709",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "<FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46db5a88-23f1-46b2-9d32-d8e4eeb9f5a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "%sql\n",
    "select * from model_logs_drift_metrics\n",
    "where drift_type = 'BASELINE' AND slice_key is null and column_name = 'BMI'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91969917-6c33-441f-936b-814a63839362",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Build custom code to inspect drift using KS test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b96b068e-c91e-4355-bf0f-cf27ac0c34a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "## Load the drift metrics data from the Delta table\n",
    "drift_table =<FILL_IN>\n",
    "drift_metrics_df = <FILL_IN>\n",
    "\n",
    "## Convert to Pandas DataFrame\n",
    "data = drift_metrics_df.toPandas()\n",
    "\n",
    "## Convert Timestamp objects to strings in 'window' and 'window_cmp'\n",
    "def convert_timestamp_to_string(d):\n",
    "    if isinstance(d, dict):\n",
    "        for k, v in d.items():\n",
    "            if isinstance(v, pd.Timestamp):\n",
    "                d[k] = v.isoformat()\n",
    "            elif isinstance(v, dict):\n",
    "                d[k] = convert_timestamp_to_string(v)\n",
    "    return d\n",
    "\n",
    "data['window'] = data['window'].apply(<FILL_IN>)\n",
    "data['window_cmp'] = data['window_cmp'].apply(<FILL_IN>)\n",
    "\n",
    "## Ensure JSON fields are strings\n",
    "data['window'] = data['window'].apply(json.dumps)\n",
    "data['window_cmp'] = data['window_cmp'].apply(json.dumps)\n",
    "\n",
    "## Convert the JSON string in 'window' and 'window_cmp' to dictionaries\n",
    "for index, row in data.iterrows():\n",
    "    row['window'] = json.loads(row['window'])\n",
    "    row['window_cmp'] = json.loads(row['window_cmp'])\n",
    "\n",
    "## Analyze the drift metrics setting the threshold to 0.6\n",
    "drift_thresholds = <FILL_IN>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def check_drift(row):\n",
    "    ks_test_value = row['ks_test'].get('statistic') if isinstance(row['ks_test'], dict) else row['ks_test']\n",
    "    if ks_test_value is not None and ks_test_value > drift_thresholds['ks_test']:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "data['drift_detected'] = data.apply(<FILL_IN>, axis=1)\n",
    "\n",
    "## Display rows with drift detected\n",
    "drifted_rows = <FILL_IN>\n",
    "no_drifted_rows = <FILL_IN>\n",
    "\n",
    "print(\"Rows with drift detected:\")\n",
    "display(drifted_rows)\n",
    "\n",
    "print(\"\\nRows with no drift detected:\")\n",
    "display(no_drifted_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b04522d2-d676-4c21-a19d-37335e7f9668",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "## Load the drift metrics data from the Delta table\n",
    "drift_table = f\"{DA.catalog_name}.{DA.schema_name}.model_logs_drift_metrics\"\n",
    "drift_metrics_df = spark.read.table(drift_table)\n",
    "\n",
    "## Convert to Pandas DataFrame\n",
    "data = drift_metrics_df.toPandas()\n",
    "\n",
    "## Convert Timestamp objects to strings in 'window' and 'window_cmp'\n",
    "def convert_timestamp_to_string(d):\n",
    "    if isinstance(d, dict):\n",
    "        for k, v in d.items():\n",
    "            if isinstance(v, pd.Timestamp):\n",
    "                d[k] = v.isoformat()\n",
    "            elif isinstance(v, dict):\n",
    "                d[k] = convert_timestamp_to_string(v)\n",
    "    return d\n",
    "\n",
    "data['window'] = data['window'].apply(convert_timestamp_to_string)\n",
    "data['window_cmp'] = data['window_cmp'].apply(convert_timestamp_to_string)\n",
    "\n",
    "## Ensure JSON fields are strings\n",
    "data['window'] = data['window'].apply(json.dumps)\n",
    "data['window_cmp'] = data['window_cmp'].apply(json.dumps)\n",
    "\n",
    "## Convert the JSON string in 'window' and 'window_cmp' to dictionaries\n",
    "for index, row in data.iterrows():\n",
    "    row['window'] = json.loads(row['window'])\n",
    "    row['window_cmp'] = json.loads(row['window_cmp'])\n",
    "\n",
    "## Analyze the drift metrics\n",
    "drift_thresholds = {\n",
    "    \"ks_test\": 0.6,\n",
    "}\n",
    "\n",
    "def check_drift(row):\n",
    "    ks_test_value = row['ks_test'].get('statistic') if isinstance(row['ks_test'], dict) else row['ks_test']\n",
    "    if ks_test_value is not None and ks_test_value > drift_thresholds['ks_test']:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "data['drift_detected'] = data.apply(check_drift, axis=1)\n",
    "\n",
    "## Display rows with drift detected\n",
    "drifted_rows = data[data['drift_detected']]\n",
    "no_drifted_rows = data[~data['drift_detected']]\n",
    "\n",
    "print(\"Rows with drift detected:\")\n",
    "display(drifted_rows)\n",
    "\n",
    "print(\"\\nRows with no drift detected:\")\n",
    "display(no_drifted_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2fb00a76-bff9-4b89-93f8-62276bb34ab2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Lineage and Alerts for Drift Detection\n",
    "\n",
    "The following instructions are not meant to send you an alert to any device. It is only to demonstrate how to use lineage alongside alerts for your metric tables.\n",
    "\n",
    "1. **Navigate to Queries**:\n",
    "   - On the left-hand sidebar of the Databricks workspace, click on **Queries**.\n",
    "\n",
    "1. **Create a Query**:\n",
    "   - Click on **Create Query** in the top-right corner.\n",
    "   - Write a query to calculate the average value of the **Count** column in your profile metrics table:\n",
    "\n",
    "      ```SELECT AVG(Count) AS avg_count FROM model_logs_profile_metrics;```\n",
    "\n",
    "   - Give the Query a name like `Drift Alert 1`\n",
    "   > ****Note:**** Before running the query, make sure to set the current catalog and schema, and follow the `catalog.schema.table_name` structure.\n",
    "   - Once the query is complete, click **Save** to save it.\n",
    "\n",
    "1. **Create an Alert**:\n",
    "   - Navigate to **Alerts** on the left-hand sidebar and click **Create Alert**.\n",
    "   - Provide the alert with a **name** like `Test alert`.\n",
    "   - In the SQL editor panel, paste the query you have saved before.\n",
    "> ****Note:**** Before running the query, make sure to set the current catalog and schema, and follow the `catalog.schema.table_name` structure.\n",
    "   - Click the **Run all** button to validate the query.\n",
    "   - Define a **Trigger Condition**:\n",
    "     - Example: Trigger the alert when the value is above 20.\n",
    "   - Click **Test condition**.\n",
    "     - If the result satisfies the condition, you’ll see:`Triggered: Alert will trigger based on current data.`\n",
    "   - Under **Notify**, search and add users or destinations. \n",
    "   - Finally, click **View alert** and Set the **Schedule**.\n",
    "1. **Monitor Lineage and Updates**:\n",
    "   - Go back to the **Catalog** on the left sidebar.\n",
    "   - Navigate to your **model_logs_profile_metrics** table.\n",
    "   - Click on **Lineage** and then see the queries associated with this table.\n",
    "      - You will see the `Drift Alert 1` listed there.\n",
    "   - Whenever there’s an update or drift detected in your model or dataset, the alert will notify you automatically. You can then go to the table's **Lineage** tab to investigate the issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd539a24-1d3d-434d-a712-b90cb476fbfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this lab, you learned how to programmatically setup Lakehouse Monitoring on an inference table for detecting drift. This included investigating the automatically generated dashboard as well as the two metric tables: profile metrics and drift metrics. Additionally, you set up an alert use SQL to notify you when you suspect drifting may occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5cce394c-1246-40b6-aecd-7c71c3942996",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2026 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "3.2 Lab - Monitoring Drift with Lakehouse Monitoring",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
