{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "233ea6c5-1db7-4c35-83a3-973b6b1052fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Model Evaluation and Testing\n",
    "This notebook evaluates the performance of the trained model, validates predictions, and prints the accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "594a61b3-229f-4149-bc8e-2457eb230411",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Classroom Setup\n",
    "\n",
    "Before starting the demo, run the provided classroom setup script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f68d73fc-63b0-4340-99bd-379837ee6760",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./Classroom-Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5af3c15a-7ef7-4806-8405-b3d7eb0df6d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Widgets for environment-specific configurations\n",
    "dbutils.widgets.dropdown(\"env\", \"dev\", [\"dev\", \"staging\", \"prod\"], \"Environment Name\")\n",
    "dbutils.widgets.text(\"model_name\", \"diabetes_model_dev\", \"Model Name\")\n",
    "dbutils.widgets.text(\"accuracy_threshold\", \"0.6\", \"Accuracy Threshold\")\n",
    "\n",
    "# Initialize output dictionary\n",
    "output_results = {}\n",
    "\n",
    "# Get environment and model name from widgets\n",
    "env = dbutils.widgets.get(\"env\")\n",
    "model_name = dbutils.widgets.get(\"model_name\")\n",
    "accuracy_threshold = float(dbutils.widgets.get(\"accuracy_threshold\"))\n",
    "\n",
    "# Define the catalog, schema, and table paths\n",
    "feature_data_path = f\"{DA.catalog_name}.{DA.schema_name}.feature_engineered_data\"\n",
    "full_model_name = f\"{DA.catalog_name}.{DA.schema_name}.{model_name}\"\n",
    "\n",
    "# Load feature-engineered data\n",
    "try:\n",
    "    feature_data = spark.table(feature_data_path)\n",
    "    feature_count = feature_data.count()\n",
    "    if feature_count == 0:\n",
    "        raise ValueError(\"The feature-engineered dataset is empty. Ensure the data transformation step completed successfully.\")\n",
    "    else:\n",
    "        print(f\"Feature data contains {feature_count} rows.\")\n",
    "        output_results[\"feature_data_count\"] = feature_count\n",
    "        feature_data.printSchema()\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to load feature-engineered data: {e}\")\n",
    "\n",
    "# Ensure required columns are present\n",
    "required_columns = [\n",
    "    \"HighBP\", \"BMI\", \"Smoker\", \"PhysActivity\", \"Fruits\", \n",
    "    \"Veggies\", \"MentHlth_squared\", \"BMI_squared\", \n",
    "    \"BMI_MentHlth_interaction\", \"Age\"\n",
    "]\n",
    "missing_columns = [col for col in required_columns if col not in feature_data.columns]\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"Missing columns in feature_data: {missing_columns}\")\n",
    "\n",
    "# Create feature vector\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=required_columns,\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    feature_data = assembler.transform(feature_data)\n",
    "    vector_count = feature_data.count()\n",
    "    if vector_count == 0:\n",
    "        raise ValueError(\"The feature_data DataFrame is empty after vector assembly. Check the input data and transformation logic.\")\n",
    "    print(f\"Feature vector successfully created with {vector_count} rows.\")\n",
    "    output_results[\"feature_vector_count\"] = vector_count\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Vector assembly failed: {e}\")\n",
    "\n",
    "# Verify model compatibility\n",
    "from mlflow.tracking import MlflowClient\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "try:\n",
    "    client = MlflowClient()\n",
    "    model_version = 1  # Replace with the actual version number or use a custom alias\n",
    "    model_uri = f\"models:/{full_model_name}/{model_version}\"\n",
    "    print(f\"Attempting to load model from Unity Catalog URI: {model_uri}\")\n",
    "    model = mlflow.spark.load_model(model_uri)\n",
    "    print(f\"Loaded model from: {model_uri}\")\n",
    "except mlflow.exceptions.MlflowException as e:\n",
    "    raise ValueError(f\"Failed to load the model from Unity Catalog. Ensure the model '{full_model_name}' is registered and available in Unity Catalog. Error: {e}\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"An unexpected error occurred while loading the model from Unity Catalog: {e}\")\n",
    "\n",
    "# Generate predictions\n",
    "try:\n",
    "    predictions = model.transform(feature_data)\n",
    "    prediction_count = predictions.count()\n",
    "    if prediction_count == 0:\n",
    "        raise ValueError(\"The model failed to generate any predictions. Check the input features and model compatibility.\")\n",
    "    print(f\"Predictions generated successfully: {prediction_count} rows.\")\n",
    "    output_results[\"predictions_count\"] = prediction_count\n",
    "    \n",
    "    predictions.write.mode(\"overwrite\").saveAsTable(f\"{DA.catalog_name}.{DA.schema_name}.prediction_table\")\n",
    "    print(f\"Predictions saved to table: {DA.catalog_name}.{DA.schema_name}.prediction_table\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to generate predictions: {e}\")\n",
    "\n",
    "# Evaluate the model\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "try:\n",
    "    evaluator = RegressionEvaluator(\n",
    "        labelCol=\"Diabetes_binary\", \n",
    "        predictionCol=\"prediction\", \n",
    "        metricName=\"rmse\"\n",
    "    )\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "    output_results[\"rmse\"] = rmse\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to evaluate the model: {e}\")\n",
    "\n",
    "# Evaluate model predictions\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"Diabetes_binary\", \n",
    "    rawPredictionCol=\"prediction\", \n",
    "    metricName=\"areaUnderROC\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print(f\"Model accuracy: {accuracy}\")\n",
    "    output_results[\"model_accuracy\"] = accuracy\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to evaluate the model accuracy: {e}\")\n",
    "\n",
    "# Save output results to a JSON file\n",
    "output_file_path = \"./model_evaluation_output.json\"\n",
    "with open(output_file_path, \"w\") as f:\n",
    "    json.dump(output_results, f, indent=4)\n",
    "\n",
    "print(f\"Model Evaluation Output Results:\\n{json.dumps(output_results, indent=4)}\")\n",
    "print(f\"Output results saved to {output_file_path}\")\n",
    "\n",
    "# Final decision\n",
    "if accuracy >= accuracy_threshold:\n",
    "    print(\"Notebook exited: SUCCESS\")\n",
    "    dbutils.notebook.exit(\"SUCCESS\")\n",
    "else:\n",
    "    print(\"Notebook exited: FAILURE\")\n",
    "    dbutils.notebook.exit(\"FAILURE\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "evaluate_model",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
