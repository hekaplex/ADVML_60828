{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1159a05b-b0f5-4832-9182-4320287dedb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Model Evaluation with Accuracy Check\n",
    "This notebook evaluates the trained model's accuracy and determines if the pipeline should proceed or stop based on a threshold.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5b87482-1266-43ca-abb4-c4a3e52f66b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Requirements\n",
    "\n",
    "Please review the following requirements before starting the lesson:\n",
    "\n",
    "* To run this notebook, you need a classic cluster running one of the following Databricks runtime(s): **17.3.x-cpu-ml-scala2.13**. **Do NOT use serverless compute to run this notebook**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a20e5241-7cfb-40d9-8f9c-56f5ec50031a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Classroom Setup\n",
    "\n",
    "Before starting the demo, run the provided classroom setup script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af3092c0-3fe3-44bc-bd74-339ff807a977",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../../../Includes/Classroom-Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41d1f08a-1947-41c6-89a8-20ff05c44b77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Widgets for environment-specific configurations\n",
    "dbutils.widgets.text(\"accuracy_threshold\", \"0.6\", \"Accuracy Threshold\")\n",
    "dbutils.widgets.text(\"model_name\", \"diabetes_model_dev\", \"Model Name\")\n",
    "\n",
    "# Get values from widgets\n",
    "accuracy_threshold = float(dbutils.widgets.get(\"accuracy_threshold\"))\n",
    "model_name = dbutils.widgets.get(\"model_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "616600ac-a295-446d-9b1a-24a25553eb42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate model predictions\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"Diabetes_binary\", \n",
    "    rawPredictionCol=\"prediction\", \n",
    "    metricName=\"areaUnderROC\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a58ed43-fb67-4fe9-9b12-5aa7f3fcfa9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Load the predictions\n",
    "    predictions = spark.sql(f\"SELECT * FROM {DA.catalog_name}.{DA.schema_name}.prediction_table\")\n",
    "    \n",
    "    # Evaluate the accuracy\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    display(f\"Model accuracy: {accuracy}\")\n",
    "    \n",
    "    # Check accuracy threshold\n",
    "    if accuracy >= accuracy_threshold:\n",
    "        display(f\"Model accuracy {accuracy} meets the threshold {accuracy_threshold}. Proceeding with the pipeline.\")\n",
    "        dbutils.notebook.exit(\"SUCCESS\")\n",
    "    else:\n",
    "        display(f\"Model accuracy {accuracy} is below the threshold {accuracy_threshold}. Stopping the pipeline.\")\n",
    "        dbutils.notebook.exit(\"FAILURE\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to evaluate the model accuracy: {e}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "accuracy_check",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
