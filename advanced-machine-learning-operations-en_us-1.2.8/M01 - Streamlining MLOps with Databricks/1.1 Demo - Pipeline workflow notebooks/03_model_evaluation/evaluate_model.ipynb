{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21af376d-a768-4200-b384-1780a1a7a64d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Model Evaluation and Testing\n",
    "This notebook evaluates the performance of the trained model, validates predictions, and includes deliberate errors for troubleshooting exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9dec5ec4-16df-4a86-9672-f7bf80f98d7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Requirements\n",
    "\n",
    "Please review the following requirements before starting the lesson:\n",
    "\n",
    "* To run this notebook, you need a classic cluster running one of the following Databricks runtime(s): **17.3.x-cpu-ml-scala2.13**. **Do NOT use serverless compute to run this notebook**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d409cc4-88bf-4241-8b60-62d26e67a14b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Classroom Setup\n",
    "\n",
    "Before starting the demo, run the provided classroom setup script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "715b2adc-a4ae-47bf-8da4-4d87944479da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../../../Includes/Classroom-Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1539643-311c-4679-8546-37aeee11529d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Widgets for environment-specific configurations\n",
    "dbutils.widgets.dropdown(\"env\", \"dev\", [\"dev\", \"staging\", \"prod\"], \"Environment Name\")\n",
    "dbutils.widgets.text(\"model_name\", \"diabetes_model_dev\", \"Model Name\")\n",
    "\n",
    "# Get environment and model name from widgets\n",
    "env = dbutils.widgets.get(\"env\")\n",
    "model_name = dbutils.widgets.get(\"model_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe59ad38-d259-476b-8e37-4bc32f3714e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the catalog, schema, and table paths\n",
    "feature_data_path = f\"{DA.catalog_name}.{DA.schema_name}.feature_engineered_data\"\n",
    "full_model_name = f\"{DA.catalog_name}.{DA.schema_name}.{model_name}\"\n",
    "\n",
    "# Load feature-engineered data\n",
    "try:\n",
    "    feature_data = spark.table(feature_data_path)\n",
    "    if feature_data.count() == 0:\n",
    "        raise ValueError(\"The feature-engineered dataset is empty. Ensure the data transformation step completed successfully.\")\n",
    "    else:\n",
    "        print(f\"Feature data contains {feature_data.count()} rows.\")\n",
    "        feature_data.printSchema()\n",
    "        display(feature_data)\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to load feature-engineered data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96c00070-87a2-4fbf-ac6a-0316efb0e269",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ensure required columns are present\n",
    "required_columns = [\n",
    "    \"HighBP\", \"BMI\", \"Smoker\", \"PhysActivity\", \"Fruits\", \n",
    "    \"Veggies\", \"MentHlth_squared\", \"BMI_squared\", \n",
    "    \"BMI_MentHlth_interaction\", \"Age\"\n",
    "]\n",
    "\n",
    "missing_columns = [col for col in required_columns if col not in feature_data.columns]\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"Missing columns in feature_data: {missing_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df01d5c5-169d-476e-8221-ecaf52824c99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create feature vector\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=required_columns,\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    feature_data = assembler.transform(feature_data)\n",
    "    if feature_data.count() == 0:\n",
    "        raise ValueError(\"The feature_data DataFrame is empty after vector assembly. Check the input data and transformation logic.\")\n",
    "    print(f\"Feature vector successfully created with {feature_data.count()} rows.\")\n",
    "    display(feature_data)\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Vector assembly failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3ff9e7b-2373-478b-94b8-ecb8e8751d1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Verify model compatibility\n",
    "from mlflow.tracking import MlflowClient\n",
    "import mlflow\n",
    "\n",
    "# Set the registry URI to Unity Catalog\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "try:\n",
    "    client = MlflowClient()\n",
    "    model_version = 1  # Replace with the actual version number or use a custom alias\n",
    "    model_uri = f\"models:/{full_model_name}/{model_version}\"\n",
    "    print(f\"Attempting to load model from Unity Catalog URI: {model_uri}\")\n",
    "    model = mlflow.spark.load_model(model_uri)\n",
    "    print(f\"Loaded model from: {model_uri}\")\n",
    "except mlflow.exceptions.MlflowException as e:\n",
    "    raise ValueError(f\"Failed to load the model from Unity Catalog. Ensure the model '{full_model_name}' is registered and available in Unity Catalog. Error: {e}\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"An unexpected error occurred while loading the model from Unity Catalog: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfea0653-6bc6-49ea-9fe8-86bad8eff806",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "try:\n",
    "    predictions = model.transform(feature_data)\n",
    "    if predictions.count() == 0:\n",
    "        raise ValueError(\"The model failed to generate any predictions. Check the input features and model compatibility.\")\n",
    "    print(f\"Predictions generated successfully: {predictions.count()} rows.\")\n",
    "    display(predictions)\n",
    "    \n",
    "    # Save predictions to a table\n",
    "    predictions.write.mode(\"overwrite\").saveAsTable(f\"{DA.catalog_name}.{DA.schema_name}.prediction_table\")\n",
    "    print(f\"Predictions saved to table: {DA.catalog_name}.{DA.schema_name}.prediction_table\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to generate predictions: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f91ef64-4603-46c5-9e48-49a757236d0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "try:\n",
    "    evaluator = RegressionEvaluator(\n",
    "        labelCol=\"Diabetes_binary\", \n",
    "        predictionCol=\"prediction\", \n",
    "        metricName=\"rmse\"\n",
    "    )\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to evaluate the model: {e}\")\n",
    "\n",
    "# Log evaluation metrics to MLflow\n",
    "experiment_name = f\"/Shared/{DA.username}_adv_mlops_demo_diabetes\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"environment\", env)\n",
    "    mlflow.log_metric(\"evaluation_rmse\", rmse)\n",
    "    print(\"Evaluation metrics logged to MLflow.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "evaluate_model",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
