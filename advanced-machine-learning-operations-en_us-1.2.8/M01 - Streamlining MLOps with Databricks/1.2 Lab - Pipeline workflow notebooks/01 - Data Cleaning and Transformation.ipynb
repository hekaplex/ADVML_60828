{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f54baa6-235e-4962-aadc-94b876a44ed3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd7dabde-fd80-4099-afd9-045ab017edf4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Data Cleaning and Transformation\n",
    "This notebook handles the cleaning and transformation of the Telco customer churn dataset. It ensures the dataset is ready for further analysis and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4adf15e3-69d6-4758-ba02-fd4699133dbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Requirements\n",
    "\n",
    "Please review the following requirements before starting the lesson:\n",
    "\n",
    "* To run this notebook, you need a classic cluster running one of the following Databricks runtime(s): **17.3.x-cpu-ml-scala2.13**. **Do NOT use serverless compute to run this notebook**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77145c1e-9989-4ea3-90f6-2c12f571fce0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Classroom Setup\n",
    "\n",
    "Before starting the lab, run the provided classroom setup script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f1e44470-64ab-4a3a-9abe-9a002baa9715",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../../Includes/Classroom-Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f446ad8-87d4-440a-afc2-d2bb548e76ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Steps Covered:\n",
    "- Clean the dataset by handling missing values and outliers.\n",
    "- Perform feature engineering for additional insights and prepare the data for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2416523-5f06-4f3a-91a7-a7d2162d33bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pyspark.sql.functions import col, when, mean\n",
    "\n",
    "# Define the dataset path\n",
    "data_path = f\"{DA.paths.datasets.telco}/telco/telco-customer-churn-noisy.csv\"\n",
    "\n",
    "# Read the dataset\n",
    "raw_data = (\n",
    "    spark.read.option(\"header\", True)\n",
    "    .option(\"inferSchema\", True)\n",
    "    .csv(data_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f6337e8-401f-4a0e-a24c-1a46dabaa58f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Replace missing values in numeric columns with their mean\n",
    "columns_to_clean = [col_name for col_name in raw_data.columns if raw_data.select(col_name).schema[0].dataType.typeName() in ['double']]\n",
    "for column in columns_to_clean:\n",
    "    mean_value = raw_data.select(mean(col(column)).alias(\"mean\")).first()[\"mean\"]\n",
    "    raw_data = raw_data.fillna({column: mean_value})\n",
    "\n",
    "# Fill missing string values with \"Unknown\"\n",
    "string_columns = [col_name for col_name in raw_data.columns if raw_data.select(col_name).schema[0].dataType.typeName() == 'string']\n",
    "for column in string_columns:\n",
    "    raw_data = raw_data.fillna({column: \"Unknown\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "614c946b-a18e-4981-9a95-392c46f9cd80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Add a risk label for churn\n",
    "cleaned_data = raw_data.withColumn(\n",
    "    \"churn_risk_label\",\n",
    "    when(col(\"Churn\") == \"Yes\", \"High Risk\").otherwise(\"Low Risk\")\n",
    ")\n",
    "# Display cleaned data\n",
    "display(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3e6d939-0b45-4102-b284-7edfedde59a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Save the cleaned data\n",
    "cleaned_data_path = f\"{DA.catalog_name}.{DA.schema_name}.cleaned_telco_data\"\n",
    "cleaned_data.write.format(\"delta\").mode(\"overwrite\").saveAsTable(cleaned_data_path)\n",
    "print(f\"Cleaned data saved to: {cleaned_data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "361995e6-f09d-48bc-95d0-fda6fe5e239c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, log, sqrt, when\n",
    "\n",
    "# Feature engineering\n",
    "transformed_data = cleaned_data \\\n",
    "    .withColumn(\"log_tenure\", log(col(\"tenure\") + 1)) \\\n",
    "    .withColumn(\"sqrt_MonthlyCharges\", sqrt(col(\"MonthlyCharges\") + 1)) \\\n",
    "    .withColumn(\"log_TotalCharges\", log(col(\"TotalCharges\") + 1)) \\\n",
    "    .withColumn(\"is_senior\", when(col(\"SeniorCitizen\") == 1, \"Yes\").otherwise(\"No\"))\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = [\"customerID\", \"PhoneService\"]  # Example columns to drop\n",
    "transformed_data = transformed_data.drop(*columns_to_drop)\n",
    "\n",
    "# Display transformed data\n",
    "display(transformed_data)\n",
    "\n",
    "# Step 6: Save the transformed data\n",
    "transformed_data_path = f\"{DA.catalog_name}.{DA.schema_name}.transformed_telco_data\"\n",
    "transformed_data.write.format(\"delta\").mode(\"overwrite\").saveAsTable(transformed_data_path)\n",
    "print(f\"Transformed data saved to: {transformed_data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cda0a19c-6954-454a-8a9d-4abef5738881",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2026 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "01 - Data Cleaning and Transformation",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
