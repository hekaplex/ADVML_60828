{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00a7aa22-0062-499b-807b-72b55c6cd185",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f95de98-eaff-429f-b3d5-c3651de23446",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize DBAcademyHelper\n",
    "DA = DBAcademyHelper() \n",
    "DA.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a4ab0d3-5677-4929-af94-ce1d1bc5dc91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the wine dataset from Delta table\n",
    "data_path = f\"{DA.paths.datasets.wine_quality}/data\"\n",
    "df = spark.read.format(\"delta\").load(data_path)\n",
    "\n",
    "# Define feature columns and label column\n",
    "feature_columns = [\"fixed_acidity\", \n",
    "                   \"volatile_acidity\", \n",
    "                   \"citric_acid\", \n",
    "                   \"residual_sugar\", \n",
    "                   \"chlorides\", \n",
    "                   \"free_sulfur_dioxide\", \n",
    "                   \"total_sulfur_dioxide\", \n",
    "                   \"density\", \n",
    "                   \"pH\", \n",
    "                   \"sulphates\", \n",
    "                   \"alcohol\"]\n",
    "                   \n",
    "label_column = \"quality\"\n",
    "\n",
    "# Assemble the feature vector using VectorAssembler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "df = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0245b46-4599-4a38-95f6-e3efde656aaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "# Drop the 'ID' column if it already exists\n",
    "if \"ID\" in df.columns:\n",
    "    df = df.drop(\"ID\")\n",
    "\n",
    "# Add a new 'ID' column\n",
    "df = df.withColumn(\"ID\", monotonically_increasing_id().cast(\"int\"))\n",
    "\n",
    "# Overwrite the Delta table (avoid schema merge issues)\n",
    "df.write.format(\"delta\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(f\"{DA.catalog_name}.{DA.schema_name}.wine_quality_features\")\n",
    "\n",
    "print(f\"Successfully saved table: {DA.catalog_name}.{DA.schema_name}.wine_quality_features\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "Classroom-Setup-02.1a",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
